\documentclass[12pt]{article}

\usepackage{amsthm,amsmath,amssymb,indentfirst,float}
\usepackage{verbatim}
\usepackage[sort,longnamesfirst]{natbib}
\newcommand{\pcite}[1]{\citeauthor{#1}'s \citeyearpar{#1}}
\newcommand{\ncite}[1]{\citeauthor{#1}, \citeyear{#1}}

\usepackage{setspace}
\usepackage[margin=1in]{geometry}

%\geometry{hmargin=2.5cm,vmargin={2.5cm,2.5cm},nohead,footskip=0.5in}
\usepackage{times}

\usepackage{amsbsy,amsmath,amsthm,amssymb,graphicx}

\setlength{\baselineskip}{0.3in} \setlength{\parskip}{.05in}


\newcommand{\gbar}{\bar g}
\newcommand{\cvgindist}{\overset{\text{d}}{\longrightarrow}}
\DeclareMathOperator{\PR}{Pr} \DeclareMathOperator{\var}{Var}
\DeclareMathOperator{\cov}{Cov}
\newcommand{\eps}{\epsilon}
\newtheorem{claim}{Claim}

\newcommand{\sX}{{\mathsf X}}
\newcommand{\tQ}{\tilde Q}
\newcommand{\cU}{{\cal U}}
\newcommand{\cX}{{\cal X}}
\newcommand{\tbeta}{\tilde{\beta}}
\newcommand{\tlambda}{\tilde{\lambda}}
\newcommand{\txi}{\tilde{\xi}}



\def\baro{\vskip  .2truecm\hfill \hrule height.5pt \vskip  .2truecm}
\def\barba{\vskip -.1truecm\hfill \hrule height.5pt \vskip .4truecm}


\author{}
\date{}
\doublespacing
\begin{document}
 \centerline{\large \bf Generalized Linear Mixed Models via Monte Carlo Likelihood Approximation}
 
 \centerline{\large  Short Title: Monte Carlo Likelihood Approximation}
 
 \centerline{ http://users.stat.umn.edu/~christina/SummerofCode.pdf}
 \centerline{Christina Knudson}
 \medskip
 
\noindent{\textbf{Bio}}

I'm a doctoral candidate at the University of Minnesota's School of Statistics.  I am ABD and about a year away from graduating.  I earned my BA in Math from Carleton College and graduated magna cum laude.  I was born and raised in Decorah, Iowa, which is one of the top 20 small towns in America (according to Smithsonian Magazine).  

I started coding in the spring of 2007, first in Python and then Java. I started using R during the summer of 2007 at the Summer Institute for Training in Biostatistics, then continued programming with R during my summer internship at the National Institutes of Health in 2008.  Most of my graduate coursework has been in R, and I have taught undergraduate classes in R at the University of Minnesota as well.  Part of my work for my doctoral thesis is an R package that fits Generalized Linear Mixed Models (GLMMs) using Monte Carlo Likelihood Approximation (MCLA).  I have written part of my package already and I plan to expand and generalize it this summer.
 \medskip

\noindent{\textbf{Contact Information}}\\
Student name: Christina Knudson\\
Link id: knud0158\\
Student postal address: 1901 Minnehaha Ave, Apt 317, Minneapolis MN, 55404\\
Telephone: 1-507-384-2220\\
Emails: knud0158@umn.edu, christina@umn.edu, cknudson05@gmail.com

 \medskip

\noindent{\textbf{Student Affiliation}}\\
Institution: University of Minnesota\\
Program: Statistics \\
Stage of completion: Early 2015 \\
Contact to verify: charlie@stat.umn.edu or galin@stat.umn.edu\\
Advisors: Charles Geyer and Galin Jones
 \medskip

\noindent{\textbf{Schedule Conflicts}}\\
During August 3 through 7, I will  attend the Joint Statistical Meetings to present my research.

 \medskip

\noindent{\textbf{Mentors}}\\
Mentor names: Charles Geyer and Galin Jones\\
Mentor emails: charlie@stat.umn.edu and galin@stat.umn.edu\\
Mentor link ids: cjgeyer\\
I have been in touch with my mentors.  I meet with each of them at least weekly, and sometimes I talk to Charlie several times per week.  They are both expecting me to complete the research I have proposed.

 \medskip
\noindent{\textbf{Background}}

GLMMs are popular in many fields from ecology to economics. The 242,000 results from a Google search for ``GLMM'' show the popularity of GLMMs.  The challenge for researchers is finding an easy-to-implement and reliable method for fitting and testing GLMMs. For very simple problems with just a few random effects, the likelihood can be approximated by numerical integration.  Most models have crossed random effects, which numerical integration cannot handle. Thus, a commonly used method is penalized quasi-likelihood (PQL), which is  implemented in packages such as lme4, nlme, and MASS. However, PQL relies on approximations of unknown accuracy to approximate the likelihood and suffers from problematic inferential properties, such as parameter estimates that tend to be too low (\ncite{mccu:sear:2001}). Since the likelihood is approximated to an unknown accuracy by the quasi-likelihood, any inference performed on the approximated likelihood will also produce results with an unknown level of accuracy.  Without bootstrapping, the user cannot know how valid their confidence intervals or likelihood ratio test results are when using PQL.  The popularity of PQL despite its inadequacies shows that there is a high demand for tools to fit GLMMs.


Monte Carlo  Likelihood Approximation (MCLA) is another tool for fitting GLMMs. This method approximates the likelihood either through Markov Chain Monte Carlo (MCMC) or Ordinary Monte Carlo (OMC), and the resulting likelihood approximation is used to fit and test GLMMs (\ncite{geyer:thom:1992}).   Because MCLA approximates the entire likelihood, any type of likelihood-based inference can be performed.  Inference such as maximum likelihood or likelihood-ratio testing is standard for many simpler models, but MCLA is the only method that can perform these techniques for GLMMs.  Moreover, MCLA is supported by a rigorous theoretical foundation supplied by \citet{geyer:1994} and  \citet{sung:geyer:2007}. Despite MCLA's solid theoretical underpinnings, it is not yet a widely-used technique. MCLA via MCMC is  too difficult for most users because they do not know when the Markov chain has run long enough to produce reliable answers.  \pcite{sung:geyer:2007} version of MCMLA via OMC is more user-friendly but is limited to smaller problems.

My current work performs MCLA via OMC with an improved importance sampling distribution.  Rather than selecting an importance sampling distribution independently of the data, my  package uses an importance sampling distribution that is similar to the true distribution of the random effects.  The importance sampling distribution is specified based on the data.  With this importance sampling distribution, my package performs MCLA for GLMMs with a Poisson or Bernoulli response using the canonical link.  The package assumes the random effects are independently drawn from a normal distribution with mean 0 and unknown variances. There can be any number of fixed or random effects.  The package is in the testing stage and is nearing completion for the setting described earlier in this paragraph.  This package is part of my doctoral thesis in statistics, which I am earning at the University of Minnesota with Professors Charles Geyer and Galin Jones as my co-advisors.



\noindent{\textbf{Goals and objectives for Google Summer of Code}}

My goals are  (1) to rewrite sections of my package in C to  improve its speed, (2) write functions to perform likelihood ratio tests for comparing nested models, (3) write additional functions to fit models with correlated random effects.  



\noindent{\textbf{Details and schedule for completion}}

I consider my  goals separately. Completion of one goal does not depend on completion of the other goals, so I could work on the three goals in any order.

(1) Two steps stand out in my package as time-consuming: the step that decides the parameters for the importance sampling distribution and the step that maximizes the likelihood approximation. Because I have written functioning R code that performs these, I will be able to compare the R results to the C results to check my work.  I believe I can accomplish this goal in a month.

(2)  Hypothesis testing for nested models can be split into three cases: the nested models differ in their fixed effects but have the same variance components, the nested models differ by one variance component and possibly some fixed effects, the nested models differ by two or more variance components and possibly by some fixed effects. I have worked out the details for calculating the test statistics and p-values for the first two cases and will  be able to write the code for these two in about three weeks.  Coding the last case will take longer because I will need to determine the test statistic and its sampling distribution.  

(3) The covariance matrix for the random effects in my currently working code is diagonal, meaning the random effects are independently drawn based on one of possibly many variance components.  I would like to generalize the covariance matrix in order to fit models with time-dependence and location-dependence.  This generality would make my R package more usable and practical.  To fit these types of models, I would like to code two additional variance structures:  first-order autoregressive structure with homogenous variances and exponential decay based on the distance between observations.  I have written my current package with these future changes in mind. Coding and testing with these new covariance structures will take about a month.

I expect to complete this work by August 11.

\noindent{\textbf{Potential significance of research}}


In conclusion, researchers from all fields have created a high demand for a tool to fit and test GLMMs. I would like to make the process of fitting a GLMM as user-friendly and theoretically-grounded as fitting a linear model. My package will allow researchers to find maximum likelihood estimates for GLMMs with various covariance structures and perform likelihood ratio tests to compare the fit of nested models.  This proposed work is an extension of my current  research on the topic of using MCLA to fit GLMMs.  I am the best individual for this project because I am familiar with MCLA's current limitations and areas of possible improvement.  

\noindent{\textbf{References}}
\vspace{-2.3cm}
\renewcommand{\refname}{}
\bibliographystyle{apalike}
\bibliography{brref}


\end{document}