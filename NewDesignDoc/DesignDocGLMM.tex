\documentclass{article}

 \usepackage{url} 
\usepackage{amsthm,amsmath,amssymb,indentfirst,float}
\usepackage{verbatim}
\usepackage[sort,longnamesfirst]{natbib}
\newcommand{\pcite}[1]{\citeauthor{#1}'s \citeyearpar{#1}}
\newcommand{\ncite}[1]{\citeauthor{#1}, \citeyear{#1}}
\DeclareMathOperator{\logit}{logit}
    \DeclareMathOperator{\var}{Var}
   %  \DeclareMathOperator{\det}{det}
     \DeclareMathOperator{\diag}{diag}

\usepackage{geometry}
%\geometry{hmargin=1.025in,vmargin={1.25in,2.5in},nohead,footskip=0.5in} 
%\geometry{hmargin=1.025in,vmargin={1.25in,0.75in},nohead,footskip=0.5in} 
%\geometry{hmargin=2.5cm,vmargin={2.5cm,2.5cm},nohead,footskip=0.5in}

\renewcommand{\baselinestretch}{1.25}

\usepackage{amsbsy,amsmath,amsthm,amssymb,graphicx}

\setlength{\baselineskip}{0.3in} \setlength{\parskip}{.05in}


\newcommand{\cvgindist}{\overset{\text{d}}{\longrightarrow}}
\DeclareMathOperator{\PR}{Pr} 
\DeclareMathOperator{\cov}{Cov}


\newcommand{\sX}{{\mathsf X}}
\newcommand{\tQ}{\tilde Q}
\newcommand{\cU}{{\cal U}}
\newcommand{\cX}{{\cal X}}
\newcommand{\tbeta}{\tilde{\beta}}
\newcommand{\tlambda}{\tilde{\lambda}}
\newcommand{\txi}{\tilde{\xi}}




\title{Design Document: Monte Carlo Maximum Likelihood for Generalized Linear Mixed Models}

\author{Christina Knudson}

\begin{document}
\maketitle{}

\begin{abstract}
This design document describes the process of performing Monte Carlo maximum likelihood (MCML) for generalized linear mixed models.  First, penalized quasi-likelihood (PQL) estimates are calculated, which help generate simulated random effects. Then, the Monte Carlo likelihood approximation (MCLA)  is calculated using the simulated random effects. Next, the MCLA is maximized to find Monte Carlo maximum likelihood estimates, the corresponding Fisher Information, and other statistics. Additional inference is then possible, including confidence intervals for the parameters and likelihood ratio tests for comparing nested models.
\end{abstract}

\section{Theory}

Let $y=(y_1, \ldots, y_n)'$ be a vector of observed data. Let $u=(u_1,\ldots,u_q)'$ be a vector of unobserved random effects centered at 0 with variance matrix $D$. Let $\beta$ be a vector of $p$ fixed effect parameters and let $\nu$ be a vector of $T$ variance components for the random effects so that $D$ depends on $\nu$. Let $\theta=(\beta ,  \nu)'$ be a vector containing all unknown parameters. Then the data $y$ are distributed conditionally on the random effects according to $f_\theta(y|u)$ and the random effects are distributed according to $f_\theta(u)$. Although $f_\theta(u)$ does not actually depend on $\beta$ and $f_\theta(y|u)$ does not depend on $\nu$, we write both densities with $\theta$ to keep notation simple in future equations.

Since $u$ is unobservable, the log likelihood must be expressed by integrating out the random effects:
\begin{align}
l(\theta)=\log \int f_\theta(y|u) f_\theta(u) \; du
\end{align}
For most datasets, this integral is intractible. In these cases, performing even basic inference on the likelihood is not possible. Rather than evaluating the integral, \citet{geyer:thom:1992} suggest using a Monte Carlo approximation to the likelihood. Monte Carlo likelihood approximation (MCLA) uses an importance sampling distribution $\tilde{f}(u)$ to generate random effects $u_k, k=1, \ldots, m$ where $m$ is the Monte Carlo sample size.  MCLA theoretically works for any $\tilde{f}(u)$, but the  $\tilde{f}(u)$ chosen for this package is the mixture distribution specified in section \ref{sec:genRand}.

Then the Monte Carlo log likelihood approximation is
\begin{align}
l_{m}(\theta) &=\log \dfrac{1}{m} \sum_{k=1}^mf_\theta(y|u_k)  \dfrac{ f_\theta(u_k)   }{\tilde{f}(u_k)}\\
&= \log \dfrac{1}{m} \sum_{k=1}^m  \dfrac{ f_\theta(y,u_k)   }{\tilde{f}(u_k)}. \label{eq:MCLAval}
\end{align}
When $\tilde{f}$ depends on $\theta$, the gradient vector of the MCLA with respect to $\theta$ is
\begin{align}
\nabla l_m(\theta)&= \dfrac{\sum_{k=1}^m    \left( \nabla \log f_\theta(u_k,y) - \nabla \log \tilde{f} (u_k)  \right) \dfrac{f_\theta(u_k,y)}{\tilde{f}(u_k)} }{\sum_{k=1}^m \left( \dfrac{f_\theta(u_k,y)}{\tilde{f}(u_k)} \right) }, \label{eq:MCLAgradient}
\end{align}
and the Hessian matrix of the MCLA is
\begin{align}
&\nabla^2 l_m(\theta)= \dfrac{   \sum_{k=1}^m \left[ \nabla^2 \log f_\theta(y,u_k)  -
   \nabla^2 \log \tilde{f}(u_k)   \right]  \dfrac{ f_\theta(y,u_k)}{\tilde{f}(u_k)}  }{\sum_{k=1}^m  \dfrac{ f_\theta(y,u_k)   }{\tilde{f}(u_k)}}\\
&+ \dfrac{   \sum_{k=1}^m \left[ \nabla \log f_\theta(y,u_k)  -
   \nabla \log \tilde{f}(u_k) - \nabla l_m(\theta)   \right] \left[ \nabla \log f_\theta(y,u_k)  -
   \nabla \log \tilde{f}(u_k) -\nabla l_m(\theta)  \right]'  \dfrac{ f_\theta(y,u_k)   }{\tilde{f}(u_k)}   }{\sum_{k=1}^m  \dfrac{ f_\theta(y,u_k)   }{\tilde{f}(u_k)}}. \label{eq:MCLAhessian}
\end{align}
Details for these equations can be found in section \ref{sec:calcs}. Calculation for the gradient and hessian when $\tilde{f}$ is independent of $\theta$ can be found in section \ref{sec:calcsindep}.



Now any inference, such as maximum likelihood, can be performed on $l_m(\theta)$ and its derivatives.  









\section{Model fitting function} 
This is be the primary function the user  uses. The user  specifies the response and the predictors using the R formula mini-language as interpreted by \texttt{model.matrix}. Let $n$ be the observed sample size and recall that $p$ is the number of fixed effects.  When the fixed effects are specified, the model matrix $X$  is created, where $X$ has dimensions $n \times p$. 

The user  specifies the random effects in the same way as for the R function \texttt{reaster} in the R package
 \texttt{aster} \citep{aster-package}. That is, random effects are expressed using the R formula mini-language. Let $q_t$ be the number of random effects associated with variance component $\nu_t$. When the random effects are specified, a list of T model matrices are created and the $t$th model matrix $Z_t$ has dimensions $n \times q_t$.


The user also specifies the expontial family (details in section \ref{sec:fam}), the name of the data set, and the name of the variance components.  

Thus, the following is a sample command with fixed predictors $x_1$ and $x_2$ and with random effects created by categorical variables $school$ and $classroom$:
\begin{verbatim}
glmm(y ~ x1+ x2, list(~0+school,~0+classroom),  family.glmm="bernoulli.glmm", 
data=schooldat,varcomps.names=c("school","classroom"),varcomps.equal=c(1,2),
debug=FALSE)
 \end{verbatim} 


%$\Box$ Most of the time (but not all the time), the random effects formula should be ``0+...'' If the user does not specify ``0+'' then I want to give a warning something like ``Did you mean to start your random effects formula with 0+? Most models require this, so please check if you meant to include it.''

It is possible that the user could want some variance components to be set equal. For example, \pcite{coull:agresti:2000} influenza dataset contains four years with random effects for each year. The authors want the within-year variance components to be equal.  There are also variance components for subject-specific intercepts and for the decreased susceptibility to illness in year 4 (since the strain of flu during year 4 was a repeat of a previous year). Suppose \texttt{year} is a categorical variable with four levels, and \texttt{year1} through \texttt{year4} are dummy variables. Thus, the call  contains these arguments:
\begin{verbatim}
glmm(y~year,list(~0+subject,~0+year1,~0+year2,~0+repeat,~0+year3,~0+year4),
 varcomps.equal=c(1,2,2,3,2,2), varcomps.names=c("subject","year","repeat"),
data=flu,family.glmm=bernoulli.glmm)
\end{verbatim}

As a result of this command, \texttt{model.matrix}  makes $Z$ into a list of 6 design matrices. Since we have 3 distinct variance components, we want 3 design matrices. We take the design matrices that share a variance component and \texttt{cbind} them together. The result is 3 model matrices in the $Z$ list, one for each variance component. We  want to put them in order (1,2,3 according to \texttt{varcomps.equal}) so that the names for each model matrix  ("subject","year","repeat") are correctly assigned.  Also, the variance estimates  come out in this same order as well.
    
  After interpreting the model the user has specified, the next step is to find penalized quasi-likelihood (PQL) estimates.  The process of finding these estimates is detailed in section \ref{sec:pql}. The PQL estimates parameterize the importance sampling distribution $\tilde{f}(u_k)$ which generate the random effects.  More information on generated the random effects is in section \ref{sec:genRand}. 

Next, \texttt{trust} is implemented to maximize  the MCLA objective function (details on the objective function are in section \ref{sec:objfun}). Finally, the function  returns parameter estimates, the log likelihood evaluated at those estimates, the gradient vector of the log likelihood,  the Hessian of the log likelihood at those estimates, information from the \texttt{trust} optimization, and other information.


%%Families%%
\section{Families} \label{sec:fam}


Let $g$ be the canonical link function and $\mu$ be a vector of length $n$ such that
\begin{align}
g(\mu) = X \beta + Z U
\end{align}
The choice of the link function is related to the distribution of the data, $ f_\theta(y|u)$. If the data have a  Bernoulli distribution, the link is $\logit(\mu)$. If the data have a Poisson distribution, the link is $\log (\mu)$. Currently, \texttt{glmm} offers only these two choices for the family, but any exponential family could work and can be easily added later.

 For simplicity of future notation, let $\eta=g(\mu)=X \beta + Z U$. Let $c(\eta)$ denote the cumulant function such that the log of the data density can be written as
\begin{align}
Y' \eta - c(\eta) = \sum_i \left[ Y_i \eta_i - c(\eta_i)  \right]
\end{align}

The user is required to specify the family in the model-fitting function. Once the family is specified, many family-specific functions are called. They are contained in an S3 class called ``glmm.family''. Each family function outputs a list including the family name (a character string such as ``bernoulli.glmm''), a function that calculates the value of the cumulant function $c(\eta)$,  a function that calculates the cumulant's first derivative $c'(\eta)$ with the derivative taken with respect to $\eta$, and  a function that calculates the cumulant's second derivative $c''(\eta)$. 

The users provide the family in the model-fitting function by either enter the character string (``bernoulli.glmm''), the function (\texttt{bernoulli.glmm()}), or the result of invoking the function.  The following code for using the input to determine the family is adapted from \texttt{glm}.

\begin{verbatim}
logDensity<-function(family.glmm)
{
	if(is.character(family.glmm))
		family.glmm<-get(family.glmm,mode="function",envir=parent.frame())
	if(is.function(family.glmm))
		family.glmm<-family.glmm()
	if(!inherits(family.glmm,"glmm.family")) 
		stop(" 'family.glmm' not recognized") 
	return(family.glmm)
}
\end{verbatim}
We interpret this as follows.  If the user has entered the family as a string, go get the R object with that family name, either from the immediate environment or the parent environment.  If this has happened, \texttt{family.glmm} is now a function.  If \texttt{family.glmm} is a function (either because the user entered it as a function or because of the preceding step), invoke that function.  At this point, \texttt{family.glmm} should have  class ``\texttt{glmm.family}.'' If this is not the case (maybe because of a typo or maybe because they entered ``\texttt{poisson}'' rather than ``\texttt{poisson.glmm}''), then stop and return an error.

With this, calculating $c(\eta_i), c'(\eta_i),$ and  $c''(\eta_i)$ is as simple as: 
\begin{verbatim}
family.glmm$c(args)
family.glmm$cp(args)
family.glmm$cpp(args)
\end{verbatim}

For the Bernoulli distribution, we calculate these values (\texttt{c}, \texttt{cp}, and \texttt{cpp}) with careful computer arithmetic as follows. We also use the \texttt{log1p} function in R for $c(\eta_i)$. 
\begin{align}
c(\eta_i) &= \log(1+e^{\eta_i}) =
  \begin{cases}
    \log(1+e^{\eta_i}) & \text{if } \eta_i\leq 0,\\
    \eta_i+\log(e^{-\eta_i}+1) & \text{if } \eta_i >0,
  \end{cases}\\
c'(\eta_i)&=\dfrac{ e^{{\eta_{i}}}}{ 1+e^{{\eta_{i}}}} = \dfrac{1}{1+e^{-\eta_i}}\\
c''(\eta_i)&=   \dfrac{e^{{\eta_{i}}}}{  1+ e^{{\eta_{i}}} }  - \dfrac{e^{2{\eta_{i}}}}{    (  1+ e^{{\eta_{i}}})^2}  = \dfrac{1}{1+e^{-\eta_i}}\cdot \dfrac{1}{1+e^{\eta_i}}
\end{align}
 For poisson, these values (\texttt{c}, \texttt{cp}, and \texttt{cpp}) are
\begin{align}
c(\eta_i)&=e^{\eta_i}\\
c'(\eta_i)&=e^{{\eta_{i}}}\\
c''(\eta_i)&= e^{{\eta_{i}}}.
\end{align}

Then we use these pieces to create the scalar $c(\eta)$, the vector $c'(\eta)$ and the matrix $c''(\eta)$. We calculate

\begin{align}
c(\eta)= \sum_i c(\eta_i).
\end{align}
 The vector $c'(\eta)$ has components $c'(\eta_i)$. The matrix $c''(\eta)$ is diagonal with diagonal elements $c''(\eta_i)$.

In the R function \texttt{glm}, the user can choose the link. The canonical link must be used in the \texttt{glmm} package so that we have an exponential family. The canonical link is included in \texttt{family.glmm}  in case the user does not know it already.

Also, I have a function to check that the data are valid given the family type. If \texttt{family.glmm} is \texttt{bernoulli.glmm}, the data should be 0s or 1s. If \texttt{family.glmm} is \texttt{poisson.glmm}, then the data should be nonnegative integers.  If the data does not pass the check, the check returns an error message. 

\subsection{Redone in C}
Redone in C, I  have  separate functions for calculating $c(\eta)$, $c'(\eta)$, $c''(\eta)$: \texttt{cum3.c}, \texttt{cp3.c}, and \texttt{cpp3.c}. The inputs for each function are identical:  \texttt{eta} (an array of doubles), $\texttt{neta}$ (the length of \texttt{eta}), the type (to denote the family: $1$ indicates Bernoulli and $2$ indicates Poisson), and an array of doubles to contain the result. These are passed in as pointers. The functions  calculate  the cumulant function or one of its first two derivatives. Each function  contains a switch statement for the glmm family. The calculations for each of these functions have  been shown earlier in this section. This function is type void: rather than returning the cumulant or its derivatives, the pointers are changed to contain the results. This function is invoked by \texttt{el}, described in section \ref{sec:el}.


\section{Log density of the data (\texttt{el})}\label{sec:el}
This section provides details for the log density of the data and two of its derivatives.  

\subsection{Equations}
Recall the log of the data density is
\begin{align}
\log f_\theta(y|u) &= Y' \eta +c(\eta) \\
&= \sum_{i} Y_{i} {\eta_{i}} - c({\eta_{i}})
\end{align}
where
\begin{align}
\eta=X\beta+ZU.
\end{align}
The derivative of this with respect to one component, $\eta_j$, is
\begin{align}
\dfrac{\partial}{\partial \eta_j} \log f_\theta(y|u)  = Y_j-c'(\eta_j).
\end{align}
The derivative of the component $\eta_j$ with respect to one of the fixed effect predictors, $\beta_{l}$, is
\begin{align}
\dfrac{\partial \eta_j}{\partial \beta_{l}} = X_{j{l}}
\end{align}

We'd like the derivative of the log of the data density with respect to $\beta$. This can be written using the chain rule as follows:
\begin{align}
\dfrac{\partial}{\partial \beta_{l}}  \log f_\theta(y|u) &= \dfrac{\partial \eta_j}{\partial \beta_{l}} \dfrac{\partial}{\partial \eta_j} \log f_\theta(y|u) \\
&= \left[ Y_j-c'(\eta_j) \right]  X_{j{l}}
\end{align}

The mixed partial derivative (with respect to $\beta_{l_1}$ and $\beta_{l_2}$) of the log data density can be written similarly:
\begin{align}
\dfrac{\partial^2}{\partial \beta_{l_1} \partial \beta_{l_2}}  \log f_\theta(y|u) &=\dfrac{\partial}{\partial \beta_{l_2}} \left( \left[ Y_j-c'(\eta_j) \right]  X_{j{l_1}} \right) \\
&= \dfrac{\partial \eta_j}{\partial \beta_{l_2}} \dfrac{\partial}{\partial \eta_j} \left( \left[ Y_j-c'(\eta_j) \right]  X_{j{l_1}} \right) \\
&= -X_{j{l_1}} X_{j{l_2}} c''(\eta_j) 
 \end{align}


Letting $c'(\eta)$ be a vector with components $c'(\eta_j)$, the first derivative of the log data density can be written in matrix form as:
\begin{align}
\dfrac{\partial}{\partial \beta}  \log f_\theta(y|u) = X' \left[ Y-  c'(\eta)  \right].
\end{align}

Letting $ c(\eta)$ be a diagonal matrix with components $c''(\eta_j)$, the second derivative of the log data density can be written in matrix form as:
\begin{align}
   \frac{\partial^2}{\partial \beta^2} \log f_\theta(y|u) =   X' [ -  c''(\eta) ] X
\end{align}

\subsection{Redone in C}
The C function to calculate the value of the log data density and its two derivatives are called by reference. The following pointers are passed in: double \texttt{Y}, double \texttt{X}, int \texttt{nrowX}, int \texttt{ncolX}, double \texttt{eta}, int \texttt{family}, double \texttt{elval}, double \texttt{elgradient}, double \texttt{elhessian}. The pointers  \texttt{elval}, \texttt{elgradient} and \texttt{elhessian} are zeros before \texttt{el.C} is invoked. Invoking \texttt{el.C}  then places the calculatedvalue of the log data density and two derivatives into \texttt{elval}, \texttt{elgradient} and \texttt{elhessian}.\\

The function \texttt{el.C} calls the following C functions: \texttt{cum3.C} to calculate the cumulant given a value of $\eta$, \texttt{cp3.C} to calculate the derivative of the cumulant given a value of $\eta$, \texttt{cpp3.C} to calculate the hessian of the cumulant given a value of $\eta$, and functions to perform matrix multiplication.


\section{Random effect generation and calculations}
This section is focused on a vector of random effects $u$ with length $q$. We assume that $u \sim N(0,D)$ where $D$ depends on $\nu$. Section \ref{sec:getEk} details the  relationship between  $\nu$ and $D$ explicit. Section \ref{sec:genRand} describes the process of generating the random effects. Section \ref{sec:distRand} explains how to evaluate the distribution of the random effects and its first two derivatives.

%%getEk
\subsection{Constructing $D$ (\texttt{getEk})}\label{sec:getEk}
For this version of the package, we that assume that $D$ is diagonal.  Let $\nu$ be length $T$ with components $\nu_t$, and let $E_t,t=1,\ldots,T$ be diagonal matrices with indicators on the diagonal so that $\sum_{t=1}^T E_t = I$. That is, the diagonal entries  of $E_t$ indicate whether that random effect has $\nu_t$ as a variance component. Then $D=\sum_{t=1}^T\nu_t  E_t $.  

If $q_t$ is the number of random effects associated with variance component $\nu_t$, then $q_t$ is also the number of nonzero entries in $E_t$ and $q=\sum_{t=1}^T q_t$ is the total number of random effects in the model.  
The \texttt{model.matrix} part of \texttt{glmm} has made  \texttt{Z} into a list with $T$ design matrices (one for each distinct variance component).  In order to create $E_t$, we need to go through and count the  number of columns ($q_t$) for each design matrix $t$ in the list.
 Then $q=\sum_{t=1}^T q_t$ is the total number of random effects in the model, and $D$  has $q$ rows (and columns). Thus, each $E_t$  has $q$ rows and columns as well.  Then we know that $E_1$ has $q_1$ ones on the diagonal, followed by zeros to fill the rest of the diagonal.  $E_2$ has $q_1$ zeros, then $q_2$ ones, then zeros for the rest of the diagonal.



\subsection{Generating random effects (genRand)}\label{sec:genRand}
The model fitting function \texttt{glmm}  calls the function that generates the random effects and  stores them for future calculations. Let $s$ be a vector of length $q$ that represents the random effects on the standard normal scale. That is, $u= D^{1/2}s$. Let $\sigma$ be a vector of length $T$ with components $\sqrt{\nu_t}$.  The  PQL step of \texttt{glmm} has resulted in PQL estimates for $\beta$, $\sigma$ and  $s$ denoted by $\beta^*$, $s^*$ and $\sigma^*$. Then let
\begin{align}
A^*=\sum_{t=1}^T E_t \sigma^*_t
\end{align}\
and
\begin{align}
 D^* =A^*A^*
\end{align}
be matrices based on PQL estimates. Also, we can ``unstandardize'' our PQL-based random effects:
\begin{align}
u^*&=A^*s^*.
\end{align}

Let $p_1,p_2,p_3$ be proportions such that  $p_1+p_2+p_3=1$. Let $D$ be determined by the current iteration of \texttt{trust}. The importance sampling distribution $\tilde{f}$ is the following mixture distribution:
\begin{align}
 \tilde{f}(u) = p_1  N(u \, | \, 0, D)+p_2  N(u \, | \, u^*, D^*)+p_3  N(u \, | \, u^*, (Z'  c''(X \beta^*+Zu^*) Z +(D^*)^{-1}   )^{-1}) \label{eq:ftwiddle}
\end{align}

Therefore, the random effects are generated from the following distributions:
\begin{enumerate}
\item $N(0,I)$
\item $N(u^*,D^*)$
\item $N(u^*,(Z'  c''(X \beta^*+Zu^*) Z +(D^*)^{-1}   )^{-1})$.
\end{enumerate}

The first distribution is the multivariate standard normal, but the random effects drawn from this are scaled in the trust objective function so that their variance matrix $D$ is determined by the current iteration of trust.   The second distribution is centered at the PQL best guess of the random effect values $u^*$ and  has the PQL guess of the variance. The last distribution is centered at the PQL guess $u^*$ and has a variance based on the PQL penalized likelihood Hessian.  The idea of this last distribution is to generate random effects from a distribution whose Hessian matches that of the target distribution $f_\theta(y|u) f_\theta(u)$.

The random effects are generated by shifting and scaling a sample from a  standard normal distribution.  Suppose we want to generate a sample from a general normal distribution $N(\mu,\Sigma)$.  Let $u_k$ be a vector with length $q$ and let it denote one vector of generated random effects.  For each $k$, $k=1,\ldots,m$, draw a sample of size $q$ from the standard normal distribution. Call this sample $\breve{u}_k$. Then shift and scale it:
\begin{align}
u_k = \breve{u}_k \Sigma^{1/2} + \mu
\end{align}
so that it is a sample from $N(\mu,\Sigma)$.

This method requires $\Sigma^{1/2}$. One way to find $\Sigma^{1/2}$ is through eigendecomposition. Eigendecompositions take a little bit more time than Cholesky decompositions but are more stable. We can use eigendecomposition for $\Sigma$ to get orthogonal matrix $O$ (containing the eigenvectors) and diagonal matrix $\Lambda$ (with diagonal entries $\lambda$ being the eigenvalues of $\Sigma$).  Then
\begin{align}
\Sigma^{1/2}= O \Lambda^{1/2} O'.
\end{align}
Finding $\Lambda^{1/2}$ is as easy as taking the root of the diagonal entries.  We know that $\Sigma^{1/2}$ is correct because
\begin{align}
\Sigma^{1/2} \Sigma^{1/2} &= O \Lambda^{1/2} O'O \Lambda^{1/2} O'\\
&= O \Lambda^{1/2}\Lambda^{1/2} O'\\
&=O \Lambda O' \\
&= \Sigma.
\end{align}

 

%
%%%distribution of the random effects%%
%\subsection{Distribution of the random effects }\label{sec:distRandsec}
%This will be hidden from the user.  This section provides equations for evaluating the log of a normal distribution with a specified mean and variance. When necessary to emphasize and clarify the choice of mean $\mu$ and variance $\Sigma$ , I use the notation $ f(u|\mu,\Sigma)$ rather than $f_\theta(u)$.
%
%This section is useful for calculating $\tilde{f}(u_k)$.  This section also provides two derivatives in some cases, which is useful for evaluating $f_\theta(u_k)$ and two derivatives. These are needed for the calculation in \eqref{eq:MCLA}.
%
%Section \ref{sec:tee} contains details that are not currently implemented, but could be. In this version, all random effects are assumed to be normally distributed and all simulated random effects are generated from a normal distribution.


\subsection{Distribution of random effects is normal (\texttt{distRand})}\label{sec:distRand}
%
%  Recall that the first version of the package assumes $D$ is  diagonal. Since $U$ is normally distributed, we can write its log density as
%\begin{align}
%\log f_\theta(u) = -\dfrac{1}{2} \log |D| -\dfrac{1}{2} u' D^{-1} u
%\end{align}
%where $|D|$ denotes the determinant of $D$.  More details on the distribution of the random effects can be found in section \ref{sec:distRand}.
%

In this subsection, I discuss both the assumed distribution of the unobserved random effects $N(0,D)$ and the importance sampling distribution used to generate the simulated random effects.  The equations in this section provide  $\log f_\theta(u)$, $\nabla \log f_\theta(u)$,  $\nabla^2 \log f_\theta(u)$, $\tilde{f}(u)$, $ \nabla \tilde{f}(u)$, and $\nabla^2 \tilde{f}(u)$  for equation \ref{eq:MCLA}. 

Consider $N(\mu, \Sigma)$.  This is written with $\mu$ not necessarily $0$ so that the function can be used for $\tilde{f}(u)$ as well.  We can  write the distribution  as:
\begin{align}
\log f (u| \mu, \Sigma) = (-1/2) \log |\Sigma| - (1/2) (u-\mu)' \Sigma^{-1} (u-\mu)
\end{align}

Since the first version of the package assumes $D$ is diagonal, formulas involving $D$ are found in section \ref{sec:Ddiag}.  
Since random effects are also generated from a normal with nondiagonal variance matrix, we also need to evaluate $f(u|\mu,\Sigma)$ for general covariance matrix $\Sigma$. Information on this calculation for general covariance matrix $\Sigma$ are in \ref{sec:Dgeneral}).

\subsubsection{$\Sigma=D$ Diagonal}\label{sec:Ddiag}
This section provides the equations for $\log f_\theta(u)$ and  $\log \tilde{f}(u)$ and their first two derivatives.

 Recall that for every $\nu_t$, we can construct a matrix $E_t$ (with dimensions the same as matrix $D$) that has 1s on the diagonal elements corresponding to the elements of D that contain $\nu_t$ and 0s  elsewhere.  

We can partition the random effects according to their variance components: $u=(U_1',...,U_T')'$.  Let $D_t$ be the variance matrix for $U_t$. $D_t$ has $q_t$ rows (and also columns). Thus $D$ can be expressed as:
\begin{align}
D = \begin{bmatrix} D_1 & \cdots & 0 \\ \vdots & \ddots & \vdots \\ 0 & \cdots & D_T \end{bmatrix}
\end{align}

Since $D$ is diagonal, it follows that $D^{-1}$ is also diagonal with diagonal entries $\dfrac{1}{\nu_1}$,...,$\dfrac{1}{\nu_T}$.  Also, the assumption that $D$ is diagonal makes calculating the determinant of $D$  easy:
\begin{align}
|D|= \nu_1^{q_1}...\nu_T^{q_T}
\end{align}

 Taking these two pieces of information into account allows us to write the log density for $U$ as follows:
\begin{align}
\log f_\theta(u) &= (-1/2) \log |D| - (1/2) (U-\mu)' D^{-1} (U-\mu)\\
&= -\dfrac{1}{2} \left[  \sum_{t=1}^T q_t \log \nu_t   \right]  -\dfrac{1}{2} \sum_{t=1}^T \left[ \dfrac{1}{\nu_t} (U_t-\mu_t)'(U_t-\mu_t)   \right]
\end{align}





%Letting $I_{q_t}$ be the identity matrix with $q_t$ rows (and columns), we can write this as a sum as follows:
%\begin{align}
%\log f_\theta(u)&= \sum_{t=1}^T \log f_\theta(u_t)\\
%&=\sum_{t=1}^T - \dfrac{1}{2} \log |D_t| - \dfrac{1}{2} (U_t-\mu_t)' D_t^{-1} (U_t-\mu_t) \\ 
%&=\sum_{t=1}^T - \dfrac{1}{2} \log |\nu_t^{q_t}| - \dfrac{1}{2 \nu_t} (U_t-\mu_t)' I_{q_t} (U_t-\mu_t) \\ 
%&=\sum_{t=1}^T - \dfrac{q_t}{2} \log \nu_t - \dfrac{1}{2 \nu_t}(U_t-\mu_t) '(U_t-\mu_t)
%\end{align}

The first and second derivatives of each summand with respect to its associated $\nu_t$ are:
\begin{align}
\dfrac{\partial}{\partial \nu_t} \log f_\theta(u_t) = - \dfrac{q_t}{2 \nu_t} + \dfrac{1}{2 \nu_t^2}(U_t-\mu_t)'(U_t-\mu_t)
\end{align}
and 
\begin{align}
\dfrac{\partial^2}{\partial \nu_t^2} \log f_\theta(u_t) = \dfrac{q_t}{2 \nu_t^2}- \dfrac{1}{\nu_t^3} (U_t-\mu_t)'(U_t-\mu_t).
\end{align}
Any other derivative is equal to 0. That is, for all $t_1 \neq t_2$,
\begin{align}
\dfrac{\partial}{\partial \nu_{t_1}} \log f_\theta(u_{t_2}) = 0.
\end{align}
Also,
\begin{align}
\dfrac{\partial}{\partial \beta} \log f_\theta(u_{t_2}) = 0.
\end{align}
Thus, if $\nu = (\nu_1,...,\nu_T)$, the gradient of the random effects distribution is the following vector of length $T$:
\begin{align}
\dfrac{\partial}{\partial \nu}  \log f_\theta(u) = \begin{bmatrix} - \dfrac{q_1}{2 \nu_1} + \dfrac{1}{2 \nu_1^2} (U_1-\mu_1) ' (U_1-\mu_1) & ... & - \dfrac{q_T}{2 \nu_T} + \dfrac{1}{2 \nu_T^2} (U_T-\mu_T) '(U_T-\mu_T)   \end{bmatrix} 
\end{align}

The Hessian matrix is the following diagonal matrix:
\begin{align}
\dfrac{\partial^2}{\partial \nu^2} \log f_\theta(u) = \begin{bmatrix} \dfrac{q_1}{2 \nu_1^2}- \dfrac{1}{\nu_1^3} U_1'U_1 & \cdots & 0 \\ \vdots & \ddots & \vdots \\ 0 & \cdots & \dfrac{q_T}{2 \nu_T^2}- \dfrac{1}{\nu_T^3 U_T'U_T} \end{bmatrix}
\end{align}
%I will create another function to take $q_t$, $U_t$, $\mu_t$ and $\nu_t$ and spit out $\dfrac{q_t}{2 \nu_t^2} - \dfrac{1}{\nu_t^3}  (U_t-\mu_t)' (U_t-\mu_t)$. Again, during the above loop of length T, I will calculate the entries for the diagonal of this Hessian matrix.

To calculate the value, gradient, and Hessian, we need to provide  $\nu$, $u$, and the list \texttt{z} (from \texttt{mod.mcml}).  The list \texttt{z} has $T$ matrices, each with the number of columns equal to $q_t$. We need $q_t,t=1,\ldots,T$ to calculate the log density and its derivatives.



The last thing we need to discuss is how to split $U$ into $U_1,...,U_T$ and $\mu$ into $\mu_1,...,\mu_T$. The same process should work for both, so let's just look at how we'd do it for $U$.  We know that the first $q_1$ items of U are $U_1$, the next $q_2$ items are $U_2$, etc.  In other words, entries 1 through $q_1$ are $U_1$. Items $q_1+1$ through $q_1+q_2$ are $U_2$, etc. In R pseudo code, this means 
\begin{verbatim}
nrand<-lapply(z,ncol) #get the number of columns from each matrix in list z
unlist(nrand) #chance the list into a vector, since each entry in the list is just a scalar

U1<- U[1 through nrand[1]] #first rule is use 1:nrand[1]
Ut<-U[sum(nrand[1:t-1]+1 through sum(nrand[1:t])]
\end{verbatim} 

Note that we don't need to actually calculate either A or D. We work only through $\nu$.

\subsubsection{Newer version of $\Sigma=D$ Diagonal}
The newer version of \texttt{distRand} (called \texttt{distRand3}) uses the same equations as those listed in \ref{sec:Ddiag}. The only difference is that the newer version is more efficient. Rather than having each call to \texttt{distRand3} recalculate which elements of $U$ belong to each $t$, this is done ahead of time in the objective function. This information is contained in vector \texttt{meow}. This is then an argument in \texttt{distRand3}.

Rewritten in C, this function takes the following as pointers: the double array \texttt{nu} that contains the variance components, the int \texttt{T} to specify the length of \texttt{nu}, the double array \texttt{mu} that contains the means of the random effects, the int array \texttt{nrandom} of length \texttt{T} that contains the number random effects from that variance component, the double array \texttt{Uvec} that contains one vector of generated random effects,  the int array \texttt{meow} that specifies how to split \texttt{u} up based on the variance components, the double array \texttt{drgradient} that  contains the resulting gradient, and the double array \texttt{drhessian} that  contains the resulting hessian.

The result of invoking the C function is  the calculation of the gradient and hessian for the distribution of the random effects. The value is  evaluated by the C function in \ref{sec:Dgeneral}.

%%distRandGeneral
\subsubsection{$\Sigma$ in general (\texttt{distRandGeneral})}\label{sec:Dgeneral}
 Recall the general form for a normal distribution with mean $\mu$ and variance $\Sigma$ is:
\begin{align}
\log f(u \,| \,\mu, \Sigma) = (1/2) \log |\Sigma^{-1}| - (1/2) (u-\mu)' \Sigma^{-1} (u-\mu)
\end{align}
 The only part of this to discuss is $|\Sigma^{-1}|$. We can use eigendecomposition to make $\Sigma^{-1}=O \Lambda O'$ where $O$ is orthogonal and $\Lambda$ is the diagonal matrix with eigenvalues. Since orthogonal matrices have determinant $\pm 1$, then $|O||O'|=1$. Thus  
\begin{align}
|\Sigma^{-1}|&=|O'| \; |\Lambda| \; |O| \\
&= |O'| \; |O| \; |\Lambda| \\
&=|\Lambda|,
\end{align}
which is just the product of the eigenvalues. The log of the determinant is calculated beforehand to save time, since this function is called $3m$ times each optimization iteration, where $m$ is again the Monte Carlo sample size.

This function is also rewritten in C with the following  passed in as pointers: double \texttt{Sigma.inv} $\Sigma^{-1}$, double \texttt{logdet} $\log |\Sigma^{-1}|$, int \texttt{nrow}, double \texttt{uvec} a vector of random effects, double {mu} $\mu$, and double \texttt{distRandGenVal}.

%\subsection{$\tilde{f}(u_k)$}
%I need to evaluate $\log \tilde{f}(u_k)$ in the objective function of trust. I can make a function using the general form for a normal distribution's density as described in the previous subsection, then use that function for the three distributions that I sampled from. Since I generated the random effects from the three distributions in proportions $p_1,p_2,p_3$, I can write 
%\begin{align}
%\log \tilde{f}(u_k) = p_1 \log f(u_k \, | \, 0, D^*)+p_2 \log f(u_k \, | \, u^*, D^*)+p_3 \log f(u_k \, | \, u^*, (Z'  c''(X \beta^*+Zu^*) Z +(D^*)^{-1}   )^{-1})
%\end{align}
%
%\subsection{Distribution of random effects is multivariate t}\label{sec:tee}
%If we want, we can draw random effects from a t distribution with location parameter $u^*$ from PQL and scale matrix $D^*$ (using the variance components estimated by PQL). These can be drawn using the package mvtnorm. This package can also give the density evaluated at certain points. I'm not sure if I'll use this or just stick to normals.

%%%%%%%%%%%%%%%%%
%\section{t distribution for generating random effects}
%Generating random effects from a normal distribution can give us some random effects from the tails of the distribution, which results in importance sampling weights that are problematically big.  To try to fix this, we can change our importance sampling distribution to a multivariate t-distribution with location parameter $\mu$, scale parameter $D$, and $\gamma$ degrees of freedom.  The pdf is proportional to 
%\begin{align}
%f(U |\theta)=  |D|^{-.5} \left[ 1+\dfrac{1}{\gamma} (U-\mu)' D^{-1}(U-\mu)   \right]^{(\gamma+p)/2}
%\end{align}
%
%Then the log density is
%\begin{align}
%\log f(U |\theta) &\propto -.5 \log |D| - \dfrac{\gamma+q}{2} \log \left[ 1+ \dfrac{1}{\gamma} (U-\mu)' D^{-1} (U-\mu)  \right] \\
%& \propto \sum_{t=1}^T \left[- .5  q_t \log \nu_t \right]- \dfrac{\gamma+q}{2} \log \left[ 1+ \dfrac{1}{\gamma} (U-\mu)' D^{-1} (U-\mu)  \right]  \\
%& \propto \sum_{t=1}^T \left[- .5  q_t \log \nu_t \right]- \dfrac{\gamma+q}{2} \log \left[ 1+ \dfrac{1}{\gamma} \sum_{t=1}^T \dfrac{1}{\nu_t} (U_t-\mu_t)' (U_t-\mu_t)  \right]  \\\end{align}
%Its first derivative with respect to $\nu_t$ is
%\begin{align}
%\dfrac{\partial}{\partial \nu_t} \log f(U |\theta) &= \dfrac{- q_t}{2 \nu_t} + \dfrac{\gamma+q}{2} \dfrac{\dfrac{1}{\gamma \nu_t^2}(U_t-\mu_t)' (U_t-\mu_t)}{1+ \dfrac{1}{\gamma} \sum_{t=1}^T \dfrac{1}{\nu_t} (U_t-\mu_t)' (U_t-\mu_t)}
%\end{align}
%Its second derivative with respect to $\nu_t$ is
%
%\begin{align}
%\dfrac{\partial^2}{\partial \nu_t^2} \log f(U |\theta) &= \dfrac{q_t}{2 \nu_t^2} - \dfrac{\gamma+q}{2} \left[ \dfrac{\dfrac{1}{\nu_t^2 \gamma}(U_t-\mu_t)'(U_t-\mu_t)}{1+ \sum_{t=1}^T \dfrac{1}{\nu_t \gamma }(U_t-\mu_t)'(U_t-\mu_t) }  \right]^2 - \dfrac{\gamma+q}{2}  \left[ \dfrac{\dfrac{2}{\nu_t^3 \gamma}(U_t-\mu_t)'(U_t-\mu_t)}{1+ \sum_{t=1}^T \dfrac{1}{\nu_t \gamma}(U_t-\mu_t)'(U_t-\mu_t) }  \right]
%\end{align}

\subsection{Importance sampling distribution $\tilde{f}(u_k)$}\label{sec:ftwiddle}
Recall that the importance sampling distribution, first stated explicitly in equation \ref{eq:ftwiddle}, is:
\begin{align}
 \tilde{f}(u) = p_1  N(u \, | \, 0, D)+p_2  N(u \, | \, u^*, D^*)+p_3  N(u \, | \, u^*, (Z'  c''(X \beta^*+Zu^*) Z +(D^*)^{-1}   )^{-1}) 
\end{align}
Then
\begin{align}
 \log \tilde{f}(u) = \log \left( p_1  N(u \, | \, 0, D)+p_2  N(u \, | \, u^*, D^*)+p_3  N(u \, | \, u^*, (Z'  c''(X \beta^*+Zu^*) Z +(D^*)^{-1}   )^{-1}) \right)
\end{align}
Because only the first component of the mixture distribution contains any parameters,
\begin{align}
\dfrac{\partial}{\partial \nu} \log \tilde{f}(u) = \dfrac{p_1  \dfrac{\partial}{\partial \nu} N(u \, | \, 0, D)}{ p_1  N(u \, | \, 0, D)+p_2  N(u \, | \, u^*, D^*)+p_3  N(u \, | \, u^*, (Z'  c''(X \beta^*+Zu^*) Z +(D^*)^{-1}   )^{-1})}.
\end{align}
and 
\begin{align}
\nabla  \log \tilde{f}(u) = \left(0   \; \; \; \; \; \; \dfrac{\partial}{\partial \nu} \log \tilde{f}(u) \right)
\end{align}
These are used in equations \ref{eq:MCLAgr} and \ref{eq:MCLAh}. The second derivatives, which are needed in equation \ref{eq:MCLAh}, are
\begin{align}
\dfrac{\partial^2}{\partial \nu^2} \log \tilde{f}(u) &= \dfrac{p_1  \dfrac{\partial^2}{\partial \nu^2} N(u \, | \, 0, D)}{ p_1  N(u \, | \, 0, D)+p_2  N(u \, | \, u^*, D^*)+p_3  N(u \, | \, u^*, (Z'  c''(X \beta^*+Zu^*) Z +(D^*)^{-1}   )^{-1})} \\ \nonumber
&- \dfrac{p_1^2 \left( \dfrac{\partial}{\partial \nu} N(u \, | \, 0, D)\right) \left( \dfrac{\partial}{\partial \nu} N(u \, | \, 0, D)\right)'}{\left[ p_1  N(u \, | \, 0, D)+p_2  N(u \, | \, u^*, D^*)+p_3  N(u \, | \, u^*, (Z'  c''(X \beta^*+Zu^*) Z +(D^*)^{-1}   )^{-1})\right]^2}.
\end{align}
and
\begin{align}
\nabla^2 \log \tilde{f}(u_k) = \begin{bmatrix} 0 & 0 \\ 0  & \dfrac{\partial^2}{ \partial \nu^2} \log \tilde{f} (u_k)  \end{bmatrix} 
\end{align}



\section{Objective function: approximated log likelihood}\label{sec:objfun}
The objective function is optimized by \texttt{trust} within the the model fitting function.  In order to evaluate and maximize the approximated log likelihood, I need an objective function that returns the value, the gradient vector, and the Hessian matrix of the approximated log likelihood.  Recall equations \ref{eq:MCLAval}, \ref{eq:MCLAgradient}, \ref{eq:MCLAhessian}   for calculating these quantities.  This objective function needs $\log f_\theta (u_k)$, $c(\eta_i)$, $\tilde{f}(u_k)$, each of their gradient vectors, and each of their Hessian matrices to plug into these expressions.    

Denote
\begin{align}
b_k &=  \log f_\theta (u_k,y)- \log \tilde{f} (u_k) \\
&= \log f_\theta (u_k) + \log f_\theta (y|u_k) - \log \tilde{f} (u_k) \label{eq:MCLA}
\end{align}


For computational stability, we'll set $a=max(b_k)$. Then the value of the MCLA is expressed as:\\
\begin{align}
\l_m (\theta) = a+ \log \left[ \dfrac{1}{m}  \sum_{k=1}^m e^{b_k-a} \right]
\end{align}

Define the weights as:
\begin{align}
v_\theta(u_k,y) = \dfrac{e^{b_k-a}}{ \sum_{k=1}^m e^{b_k-a}} 
\end{align}

Rewriting equation \ref{eq:MCLAgradient} using the notation for the weights, the gradient vector is: 
\begin{align}
\nabla l_m(\theta) &= \sum_{k=1}^m \left( \nabla \log f_\theta (u_k,y) - \nabla \log \tilde{f}(u_k)  \right) v_\theta(u_k,y)\\ \label{eq:gradient}
&= \sum_{k=1}^m \nabla \left[  \log f_\theta(y|u_k) + \log f_\theta (u_k) - \nabla \log \tilde{f}(u_k)  \right] v_\theta(u_k,y)\\
&= \sum_{k=1}^m  \left[ \nabla \log f_\theta(y|u_k) + \nabla\log f_\theta (u_k) - \nabla \log \tilde{f}(u_k) \right] v_\theta(u_k,y)\\
&= \sum_{k=1}^m  \left[ \dfrac{\partial}{\partial \beta} \log f_\theta(y|u_k) \; \; \; \;  \dfrac{\partial}{\partial \nu} \log f_\theta(y|u_k) \right] v_\theta(u_k,y)+ \left[ \dfrac{\partial}{\partial \beta} \log f_\theta(u_k) \; \; \; \; \dfrac{\partial}{\partial \nu} \log f_\theta(u_k) \right] v_\theta(u_k,y)\\
&+  \sum_{k=1}^m  \left[ \dfrac{\partial}{\partial \beta} \log \tilde{f}(u_k) \; \; \; \;  \dfrac{\partial}{\partial \nu}  \log \tilde{f}(u_k) \right] v_\theta(u_k,y) \\
&=  \sum_{k=1}^m \left(  \left[ \dfrac{\partial}{\partial \beta} \log f_\theta(y|u_k) \; \; \; \; 0 \right] + \left[ 0 \; \; \; \; \dfrac{\partial}{\partial \nu} \log f_\theta(u_k) \right]  +\left[ 0 \; \; \; \; \dfrac{\partial}{\partial \nu} \log \tilde{f}(u_k) \right] \right) v_\theta(u_k,y)   \\
&= \sum_{k=1}^m  \left[ \dfrac{\partial}{\partial \beta} \log f_\theta(y|u_k) \; \; \; \; \left( \dfrac{\partial}{\partial \nu} \log f_\theta(u_k) \right)+\left( \dfrac{\partial}{\partial \nu} \log \tilde{f}(u_k) \right) \right] v_\theta(u_k,y) \label{eq:MCLAgr}
\end{align}

Then the Hessian matrix from equation \ref{eq:MCLAhessian} is expressed as: 
\begin{align}
&\nabla^2 l_m(\theta)=  \sum_{k=1}^m \left[ \nabla^2 \log f_\theta(y,u_k)  -
   \nabla^2 \log \tilde{f}(u_k)    \right] v_\theta(u_k,y) \label{eq:MCLAh} \\ 
&+   \sum_{k=1}^m \left[ \nabla \log f_\theta(y,u_k)  -
   \nabla \log \tilde{f}(u_k) - \nabla l_m(\theta)   \right] \left[ \nabla \log f_\theta(y,u_k)  -
   \nabla \log \tilde{f}(u_k) -\nabla l_m(\theta)  \right]'  v_\theta(u_k,y)   . \nonumber
\end{align}
Everything in this has already been defined except:
\begin{align}
\nabla^2 \log f_\theta (u_k,y) &=  \begin{bmatrix} \dfrac{\partial^2}{\partial \beta^2} \log f_\theta (u_k,y) & \dfrac{\partial^2}{\partial \beta \: \partial \nu} \log f_\theta (u_k,y) \\ \dfrac{\partial^2}{\partial \beta \: \partial \nu} \log f_\theta (u_k,y)  & \dfrac{\partial^2}{ \partial \nu^2} \log f_\theta (u_k,y)  \end{bmatrix} \\
&= \begin{bmatrix} \dfrac{\partial^2}{\partial \beta^2} \log f_\theta (u_k) & \dfrac{\partial^2}{\partial \beta \: \partial \nu} \log f_\theta (u_k) \\ \dfrac{\partial^2}{\partial \beta \: \partial \nu} \log f_\theta (u_k)  & \dfrac{\partial^2}{ \partial \nu^2} \log f_\theta (u_k)  \end{bmatrix} + 
\begin{bmatrix} \dfrac{\partial^2}{\partial \beta^2} \log f_\theta (y|u_k) & \dfrac{\partial^2}{\partial \beta \: \partial \nu} \log f_\theta (y|u_k) \\ \dfrac{\partial^2}{\partial \beta \: \partial \nu} \log f_\theta (y|u_k)  & \dfrac{\partial^2}{ \partial \nu^2} \log f_\theta (y|u_k)  \end{bmatrix} \\
&= \begin{bmatrix} 0 & 0 \\ 0  & \dfrac{\partial^2}{ \partial \nu^2} \log f_\theta (u_k)  \end{bmatrix} + 
\begin{bmatrix} \dfrac{\partial^2}{\partial \beta^2} \log f_\theta (y|u_k) & 0 \\ 0 & 0  \end{bmatrix} \\
&= \begin{bmatrix} \dfrac{\partial^2}{\partial \beta^2} \log f_\theta (y|u_k) & 0 \\ 0  & \dfrac{\partial^2}{ \partial \nu^2} \log f_\theta (u_k)  \end{bmatrix} 
\end{align}



\section{Summary of model}
Typing \texttt{summary(mod)}  gives more detailed info of the model. This is broken into two pieces (as is usually done for summaries): there will be the \texttt{summary.glmm} and \texttt{print.summary.glmm}. We split this up because we have a lot of information in the summary that we do not necessarily want printed each time. When a user types \texttt{summary(mod)}, only the  basic information is automatically printed. More information can be found in the summary list.

The summary will do all the calculations and its value will be a list of the following:
\begin{itemize}
\item call
\item the variance estimate(s)
\item a matrix with the predictor in the first column, the estimated coefficient in the second column, the standard error in the third column, the z value in the fourth column, and the two-sided pvalue  in the fifth column. All inference is asymptotic, so we use the standard normal distribution to calculate the p-values.
\item the evaluated Monte Carlo log likelihood along with its first and second derivative
\item maybe other things that I haven't thought of
\end{itemize}

A note on the standard errors: to calculate the standard errors, we take the MCLA Hessian matrix, invert it, take the diagonal elements, and square root them. It's possible that the Hessian will be noninvertible if it is close enough to singular that the computer thinks it's singular.  Then the standard errors will all be infinite. We also need to warn the user why this is happening.

Then print.summary.glmm will print these things:
\begin{itemize}
\item call
\item the variance estimate(s)
\item a matrix similar to the output of summary.glm, which will be put through printCoefmat in order to get the significance stars that we're used to. We'll have the predictor in the first column, the estimated coefficient in the second column, the standard error in the third column, the z value in the fourth column, and the two-sided pvalue  in the fifth column, the significance stars, and the significance legend.
\item maybe other things that I haven't thought of. I'll probably realize more once I get coding.
\end{itemize}

I think for the printCoefmat to work, the fixed effects matrix needs to look like
\begin{verbatim}
            Estimate Std. Error z value     Pr(>|z|)
(Intercept)        2       0.50       4 6.334248e-05
x1                 2       0.25       8 1.244192e-15
\end{verbatim}
(or at least it worked when I had these as the column names and didn't work before that).

Note that the summary and print.summary functions will be S3 generic functions.  What this means is the user will type ``summary(mod)'' and summary is a generic function. R checks the class of the model $mod$ and then automatically uses the summary and print.summary functions for that class of objects. This also might affect the way that I export the function and document it in the manual.  I think that I'll be ok if I copy parts of his summary.aster and print.summary.aster. I need to read about generics more and will check out the hints library.

\section{Checks}
\subsection{Checking the MCLA finite differences}
To check the function that calculates the MCLA $l_m(\theta)$, I use finite differences on the \citet{booth:hobert:1999} example. To do this, I chose a value of $\theta=(\beta,\sigma)$ and a relatively small value of $\delta$, where $\delta$ is a vector of length $2$. We can check that the value and first derivative of the MCLA function are calculated correctly by making sure the following approximation holds
\begin{align}
\nabla l_m (\theta)  \cdot \delta \approx l_m(\theta+\delta)-l_m(\theta).
\end{align} 
Then, we can check the first and second derivatives of the MCLA are calculated correctly by checking for the following approximation:
\begin{align}
\nabla^2 l_m (\theta) \delta \approx \nabla l_m (\theta+\delta)-\nabla l_m (\theta)
\end{align}

\subsection{Checking  functions using the Booth and Hobert example}
I also test the objective function by taking the  \citet{booth:hobert:1999} example and rewriting the functions for this specific example. I then compare the values produced by the check functions and the original functions. Functions checked this way are:
\begin{enumerate}
\item log of the data density (\texttt{el})
\item log of the density for the random effects (both \texttt{distRand} and \texttt{distRandGeneral})
\item the Monte Carlo likelihood approximation (\texttt{objfun})
\end{enumerate}

\subsection{Checking a putative MLE using MCMC}

Suppose $\hat{\theta}$ is claimed to be the MLE. For example, $\hat{\theta}$ could be the MCMLE.  Ideally, we would like to check whether the true likelihood $l(\theta)$ achieves a local max at $\hat{\theta}$.  Due to the intractible integral in the likelihood expression, the best we can do is make sure that  $\nabla l_m(\theta)$ evaluated at $\hat{\theta}$ is very close to $0$. 

Suppose $u_k,k=1,\ldots,m$ are sampled from importance sampling distribution $\tilde{f} (u_k)$. Recall that the gradient of the MCLA is:
\begin{align}
\nabla l_{m}(\theta) = \dfrac{\sum_{k=1}^m\frac{\nabla f_\theta(y|u_k) f_\theta(u_k)   }{\tilde{f}(u_k)}}{\sum_{k=1}^m \frac{  f_\theta(u_k)   }{\tilde{f}(u_k)}}
\end{align}
We can choose $\tilde{f}(u_k)=f_{\hat{\theta}}(u_k,y)$. If the putative MLE is truly the MLE, then $\theta=\hat{theta}$, which in turn implies that $\tilde{f}(u_k)=f_{{\theta}}(u_k,y)$.   To be clear, in this check  we no longer use a mixture of normals for $\tilde{f}(u_k)$.  With the selected importance sampling distribution, each of the importance sampling weights is equal to $1$ and the sum of the weights is $m$.  Therefore, the gradient of the MCLA simplifies as follows:
\begin{align}
\nabla l_{m}(\theta) &=\dfrac{1}{m} \; {\sum_{k=1}^m\dfrac{\nabla f_\theta(y|u_k) f_\theta(u_k)   }{\tilde{f}(u_k,y)}}\\
&= \dfrac{1}{m} \; {\sum_{k=1}^m\dfrac{\nabla f_\theta(u_k,y)   }{\tilde{f}(u_k,y)}} \\
&= \dfrac{1}{m} \; \sum_{k=1}^m \nabla \log f_\theta(u_k,y)
\end{align}
This shows that the gradient of the MCLA is the average of the gradient of the complete data log likelihood, as long as $\hat{\theta}$ is truly an MLE. We can produce $u_k,k=1,\ldots,m$, using Markov chain Monte Carlo. Using $u$ as the variable, w run the Markov chain (perhaps \texttt{metrop} from the R package \texttt{mcmc}) on the complete data log likelihood.  We then use these samples to calculate the gradient of the complete data log likelihood, which in turn calculates the gradient of the MCLA. 

 If we split the MCMC runs into batches, we can calculate the batch means of the MCLA gradient, the grand mean of the MCLA gradient, and the corresponding Monte Carlo standard error.  If the putative MLE truly maximizes the likelihood, then the MCLA gradient's components should be close to $0$. We can check that they are close enough to $0$ by comparing them to the Monte Carlo standard error.


\section{Likelihood ratio test}
This is another S3 generic function that the user can choose to implement if they'd  like  to do likelihood ratio tests for nested models. Eventually I'll want this to handle an arbitrary number of models, but for now we'll stick to comparing two models: $mod2$ nested in $mod1$.  I will assume these models have already been fit. 


 There are a few ways that the two models could differ. In other words, we could be testing:
 \begin{enumerate}
 \item whether one or more fixed effects are zero.
 \item whether one variance component is zero.
 \item whether multiple variance components are zero.
 \item whether one or more fixed effects is zero and one or more variance components are zero. 
\end{enumerate}
The hypothesis testing procedure and method for calculating pvalues are different for each of these cases, so I'll go through each one in the following subsubsections.

\subsection{Testing whether one or more fixed effects are zero}
Consider the  case of testing whether one or more fixed effects are zero and the random effects are the same between the two models. I think we just do a likelihood ratio test as we're familiar with for linear models.   Let the number of fixed effect parameters in the larger model be $p_1$  and the number in the nested model be $p_2$. I will need the log likelihood values of the models outputted (from the main function at the same time as when I output the MCMLEs and the Fisher information). The log likelihood is simply the ``value'' from the objective function that trust uses. Let's call the log likelihood from the larger model  $l_1$ and the log likelihood from the nested model  $l_2$. 

Then the likelihood ratio test statistic is
\begin{align}
t_{LRT}= -2l_1+2l_2
\end{align}
and this follows a $\chi^2$ distribution with $p_1-p_2$ degrees of freedom. The calculation
\begin{align}
P(t_{\chi^2_{p_1-p_2}>LRT} ).
\end{align}
gives us a two-sided pvalue to fit with the two-sided alternative hypothesis.

 
 \subsection{Testing whether one variance component is zero}
  Hypothesis testing for one variance component is easy but not what most people expect.
  In this setup, the two models have the exact same fixed effects. The only difference is the larger model has one more random effect $\nu_{t_1}$. This means we want to test whether $\nu_{t_1}=0$. A variance component must be nonnegative, meaning the alternative hypothesis is that $\nu_{t_1}>0$. In other words, the hypotheses are:
 \begin{align}
 H_0: \nu_{t_1}=0\\
 H_1: \nu_{t_1}>0.
 \end{align}
 Note the alternative hypothesis is one-sided. This means we need to calculate a one-sided pvalue. Let $t_{LRT}=2l_2-2l_1$. If we naively follow the pvalue calculation of
 \begin{align}
P( \chi^2_{1}>t_{LRT})
\end{align}
 we will end up calculating a two-sided pvalue. To fix this, we cut this pvalue in half. In other words, use the standard normal distribution $Z$ and think of calculating the one-sided pvalue this way:
 \begin{align}
 P( Z>\sqrt{|  t_{LRT} |})
 \end{align}
 
 However, this is not obvious; I never would have thought about having a test statistic of
 \begin{align}
 \sqrt{2 | l_2-l_1   |   }.
 \end{align}
 
 \subsection{Testing whether multiple variance components are zero}
 In this case, the fixed effects are identical between the larger and nested model. The only difference is that the larger model has more than one additional variance components. This gets a lot more complicated (for example, there is no clear way to count parameters so calculating the degrees of freedom is out the window). Luckily, someone's worked out the details already. Charlie suggested a few papers to look at. I'll read about and add this a bit later.  Charlie is hoping that we'll have a mixture of $\chi^2$ distributions, such as
 \begin{align}
 \dfrac{1}{2}P (\chi^2_1> t_{LRT}) +\dfrac{1}{4}P (\chi^2_2> t_{LRT}).
 \end{align}
 The reason this is complicated is because the variance components are restricted to be nonnegative. This means that the likelihood is only defined for nonnegative variance components. Then differentiating the likelihood at $0$ becomes tricky because that's the boundary.

 \subsection{Testing whether one or more fixed effects is zero and one or more variance components are zero}\label{sec:combotest}
 This seems very complicated. I don't know if it's any more complicated than the previous case of testing multiple variance components. I'll have to think about it later when I have time.
 
 \subsection{Determining the hypothesis test}
 To follow convention, this command will be called ``anova'' and the two arguments will be the two models to be compared.  The command would look like
\begin{verbatim}
anova(mod1,mod2)
\end{verbatim} 

 R will first need to figure out if the fixed effects are different and, if they are, which model is the larger model.
\begin{verbatim}
if(length(coef(mod1))>length(coef(mod2)))
      {bigmod<-mod1;  smallmod <-mod2} 
if(length(coef(mod1))<length(coef(mod2)))
      {bigmod<-mod2; smallmod <-mod1}
\end{verbatim}
Next, if there is a difference in the fixed effects, I'm going to make sure the fixed effects of the small model are nested in those of the big model. Otherwise, produce an error. Then, continue with the testing. Note: this check for nesting isn't perfect, but no other anova checks which model is bigger and whether they're nested.
\begin{verbatim}
if(big mod is defined) {
      pnames1<-names(coef(bigmod))
      pnames2<-names(coef(smallmod))
      if(sum(pnames2 %in% pnames1) != length(pnames2)) {
            stop("The models you provided are not nested.")}

     if(the variance components differ between the two models){
             check big model has more variance components (ow: error)
             check variance components of the small model are nested (ow: error)
             calculate pvalue according to section 3.3.4. return it.
      }
      if(the variance components do not differ between the two models){
            calculate pvalue according to 3.3.1. return it.
      }
}
\end{verbatim}
If and only if we've gotten to the end of this chunk of code without returning anything, bigmod has not been defined, meaning the fixed effects are same. Therefore, we now need to figure out whether the variance components differ by one or by more than one. In order to compare the number of random effects, we need to figure out how to get the number of variance components from each model. I  don't yet have a solid grasp of how formula works its magic, but I have the impression that I can count the number of model matrices returned in order to figure out the number of variance components because there is a model matrix for each one.

\begin{verbatim}
T1<- number of variance components for mod1
T2<- number of variance components for mod2
if(T1>T2){call mod1 the bigmod and mod2 the smallmod}
if(T1<T2){call mod2 the bigmod and mod1 the smallmod}
if(bigmod is defined){
     check  small model is nested in the big model (ow: error)
     (maybe do this by looking at the call?)
     if(T1==T2+1 || T2==T1+1) 
           {calculate and return pvalue according to sec 3.3.2}     
     calculate and return pvalue according to section 3.3.3
     }
if still haven't returned anything, produce error.     
\end{verbatim}	

Why the last error? If we have gotten to this point in the code with nothing returned, it ends up that the number of variance components in each model are equal, meaning the user has made some kind of mistake. Either the user provided two identical models or they provided non-nested models (e.g. they have the same number of variance components, but different components in each model). Either way, we can't help them.





This command would return something that first reminds the user what predictors are in each model, then has a table. Each model would have one row of the table. The columns would contain the model name,  the log likelihood for each model, the number of parameters in the model. Then the next columns would have one entry each: the calculated difference between the log likelihoods, the calculated difference between the number of parameters, and the pvalue of the test. 

%\section{AIC}
%Typing 
%\begin{verbatim}
%AIC(mod)
%\end{verbatim} 
%will return the AIC of the model. To calculate AIC, I'll need the total number of parameters ($p+T$)  and the Monte Carlo log likelihood evaluated at the MCMLEs $l$. Then the AIC is
%\begin{align}
%2(p+T) - 2 l 
%\end{align} 


\section{Confidence intervals}
The user can implement this command to create confidence intervals after  fitting a model $mod$ using the main function.  This is an S3 generic.The command would look like
\begin{verbatim}
confint(mod,parm,level=.95)
\end{verbatim}
The only required argument would be the fitted model (the first argument). The third argument (the confidence level) has a default of $.95$.

If the second argument is omitted, confidence intervals would be created for all of the parameters. There are two options to calculate confidence intervals for a subset of the parameters. The user can provide either  the names of the coefficients or a vector with length equal to the number of parameters (entries being 1 if they would like that intervals for that parameter and 0 otherwise).  The code to do this is taken from ``confint.lm'' and is:
\begin{verbatim}
function (object, parm, level = 0.95, ...) 
{
    cf <- coef(object)
    pnames <- names(cf)
    if (missing(parm)) 
        parm <- pnames
    else if (is.numeric(parm)) 
        parm <- pnames[parm]
        stopifnot(parm %in% pnames)
        
        rest of the code to actually do the confidence intervals goes here
        }
\end{verbatim}
What this says: write down the coefficient names of the object we're given. If parm is missing, we're going to assume they want to create intervals for all the parameters.  If parm is numeric (a vector of 0s and 1s), use that to select the parameter names we want and call that selection parm.  Finally, stop the whole process if parm (the parameter names we want intervals for) don't appear in the model.

The form for a confidence interval is the point estimate plus or minus the standard error of the point estimate times some cutoff.  The point estimate and the standard error are from the summary of the model. The reference distribution used for the cutoff is the standard normal. This will produce an asymptotic confidence interval.

The output would either be a vector of length 2 (if creating confidence interval for only one parameter) or a matrix with 2 columns (one for the lower bound of the confidence interval, one for the upper bond). The column names will be ``$(100-level)/2$'' and ``$50+level/2 $.'' (in the default case, this is``$2.5\%$'' and ``$97.5\%$'').

The only potential hangup is when creating confidence intervals for the variance components $\nu_t, t=1,...,T$.  We know that $\nu_t >0$ for all $t=1,...,T$. We'll find this boundary again makes things complicated. I don't yet know how to deal with this.  

To illustrate the problem, consider the scenario that the margin of error for $\nu_t$ is greater than the estimate of $\nu_t$ itself. It wouldn't make sense to produce a confidence interval with a negative lower bound. It could make sense to truncate the interval so that the lower bound starts at 0 and the upper bound remains untouched.  

I thought for three or four minutes about a one sided confidence interval, but I don't think that captures what we want. We want the range of all likely values for the variance component, not just an upper bound.

%
%\section{Prediction intervals}
%This is another S3 generic. The user can implement this command to create prediction intervals after  fitting a model $mod$ using the main function. Still learning about these. I currently know almost nothing. What I do know is that I will need the Monte Carlo log likelihood along with its first and second derivatives. I'll get to practice my first-year-theory delta method skills.
%
%Charlie says that neither predict.glm nor predict.glmmPQL do prediction intervals. The former produces parameter estimates with standard errors. The latter does predictions but does not produce a standard error, so no interval can be formed.
%
%One wrong thing to do: once you find the MCMLEs, you simply plug those into the distribution for $U|Y$ and pretend those parameter estimates have no variability and are  correct. Then the random effect has a normal distribution and it'd be easy to find quantiles. The only problem is this is wrong.
%
%We are hoping to find a way to use Fisher information for the Monte Carlo MLE. Hopefully we can do something more similar to the usual asymptotics.
%
%A last resort is a parametric bootstrap. I haven't spent much time thinking about this, but I think the way this involves plugging parameter estimates  into $\log f_\theta(y|u)$ and $\log f_\theta(u)$. Then you repeat: draw a value of $u$, plug that into $\log f_\theta(y|u)$, draw a value of $y$. I say this is a last resort  because having two Monte Carlo calculations will take a long time. 



\section{PQL}\label{sec:pql}
 Before we get started on describing PQL, we need to change notation to avoid constrained optimization.  Recall that $D=\var(u)$ and is (for now) assumed to be diagonal. Let $A=D^{1/2}$ so that A has diagonal components that are positive or negative. Using A rather than D enables unconstrained optimization.  If $\sigma$ is a vector of the distinct standard deviations with components $\sigma_t$, we can write A as a function of $\sigma$ by
\begin{align*}
A= \sum_t E_t \sigma_t.
\end{align*}
Recall that $E_t$ has a diagonal of indicators to show which random effects have the same variance components, and $\sum_{t=1}^T E_t$ is the identity matrix. PQL will estimate the components contained on the diagonal of A. Taking the absolute value of those components will provide the standard deviations (the square root of the variance components).

In addition to using $A$ rather than $D$, the other change is that we'll be using $s$ where $u=As$. The purpose of this is to avoid $D^{-1/2}$ in the functon we're trying to optimize.


There are two ways to do PQL, both of which are described in the vignette
 \texttt{re.pdf} in the R package \texttt{aster} (Geyer, 2014). In either case, there is an inner optimization and an outer optimization. The inner optimization is well behaved while the other optimization is a little tougher. I will be using the method that is not quite PQL but is pretty close and is better behaved.  In this version, the inner optimization finds $\tilde{\beta}$ and $\tilde{s}$ given $X$, $Z$ and $A$. Then, given $\tilde{\beta}$ and $\tilde{s}$, the outer optimization finds $A$.




The {\bf inner} optimization will be done with the trust function in R. We elect to use trust because it requires two derivatives, which will make the optimization more precise. We would like more accuracy in the inner maximization because any sloppiness will carry into the outer optimization.

The inner optimization maximizes the penalized log likelihood. After defining
\begin{align}
\eta=X\beta +ZAs
\end{align}
we calculate the  log likelihood as 
\begin{align}
l(\eta)= Y' \eta - c(\eta) 
\end{align}
and the penalized likelihood as:
\begin{align}
 l(\eta)- \dfrac{1}{2} s's.
\end{align}
This function will be maximized using the \texttt{trust} package. We need to give \texttt{trust} derivatives with respect to $s$ and $\beta$. We're going to express these via the multivariate chain rule, taking advantage of $\eta_i$.

Create  vector $\mu$ from the components $\mu_i=c'(\eta_i)$.  Since
\begin{align}
l(\eta) = \sum_i Y_i \eta_i - c(\eta_i)
\end{align}
then 
\begin{align}
\dfrac{\partial \l(\eta)}{\partial \eta_i} = Y_i-c'(\eta_i) = Y_i -\mu_i.
\end{align}
 Now we can write the following expression:

\begin{align}
%\dfrac{\partial}{\partial s_k} \left[ l(\eta)-\dfrac{1}{2} s's  \right]= \sum_i (Y_i-\mu_i) \dfrac{\partial \eta_i}{\partial s_k} \\
\dfrac{\partial}{\partial \beta_k} \left[ l(\eta)-\dfrac{1}{2} s's  \right] &= \dfrac{\partial l(\eta)}{\partial \beta_k}    \\
&= \dfrac{\partial l(\eta)}{\partial \eta_i} \dfrac{\partial \eta_i}{\partial \beta_k}    \\
&=\sum_i (Y_i-\mu_i) \dfrac{\partial \eta_i}{\partial \beta_k} \\
&=\sum_i (Y_i-\mu_i) X_{ik}
\end{align}


We find the function's derivative with respect to $s$ as follows:
\begin{align}
\dfrac{\partial }{\partial s} \left[ l(\eta) -\dfrac{1}{2} s's   \right] &= \dfrac{\partial l(\eta)}{\partial s} -\dfrac{1}{2} \dfrac{\partial s's}{\partial s}\\
&= \dfrac{\partial l(\eta)}{\partial \eta} \dfrac{\partial \eta}{\partial s} -s\\
&= (Y-\mu)' \left[ \dfrac{\partial}{\partial s} ZAs \right] -s\\
&=(Y-\mu)'ZA -s
\end{align}

This gives us the following derivatives of the penalized log likelihood:
\begin{align}
\dfrac{\partial}{\partial \beta} \left[ l(\eta)-(1/2)s's \right]&= X' (Y-\mu)\\
\dfrac{\partial}{\partial s} \left[ l(\eta)-(1/2)s's \right]&= AZ' (Y-\mu)  -s
\end{align}

Lastly, we need the Hessian of the penalized likelihood. This matrix can be broken down into four pieces: 
\begin{enumerate}
\item $ \dfrac{\partial^2}{\partial s^2}$
\item $ \dfrac{\partial^2}{\partial \beta^2}$
\item $\dfrac{\partial^2}{ \partial s \; \partial \beta}$
\item $\left(\dfrac{\partial^2}{ \partial s \; \partial \beta}\right) ' =\dfrac{\partial^2}{ \partial \beta \; \partial s}$
\end{enumerate}

We'll start at the top with  $ \dfrac{\partial^2}{\partial s^2}$, which is a $q \times q$ matrix.
\begin{align}
  \frac{\partial^2}{\partial s^2}  \left[ l(\eta) - (1/2) s's   \right] &=   \frac{\partial}{\partial s} \left[ (Y-c'(\eta))'ZA -s   \right]\\
&=\left[- \frac{\partial}{\partial s} c'(\eta)\right]'ZA - I_q \\
&= \left[-\dfrac{\partial c'(\eta)}{\partial \eta} \dfrac{\partial \eta}{\partial s}   \right] 'ZA - I_q \\
&= \left[ -c''(\eta) ZA  \right]'ZA - I_q \\
&= -AZ' \left[ c''(\eta) \right] ZA - I_q
\end{align}
Note that $c''(\eta)$ is a $q\times q$ diagonal matrix with diagonal elements $c''(\eta_i)$.  $I_q$ is the identity matrix of dimension $q$.  This makes  $ \dfrac{\partial^2}{\partial s^2}$ a $q \times q$ matrix.

Next up is  $ \dfrac{\partial^2}{\partial \beta^2}$, which is a $p \times p$ matrix.
\begin{align}
  \dfrac{\partial^2}{\partial \beta^2}  \left[ l(\eta) - (1/2) s's   \right] &=   \dfrac{\partial}{\partial \beta} \left[ X' (Y-c'(\eta))  \right]\\
&= \dfrac{\partial}{\partial \beta} \left[ X' Y-X'(c'(\eta))  \right] \\
&= \dfrac{\partial}{\partial \beta} \left[ -X'(c'(\eta))  \right] \\
&=-X  \left[' \dfrac{\partial}{\partial \beta} c'(\eta)  \right] \\
&=-X'  \left[ \dfrac{\partial  c'(\eta)}{\partial \eta} \dfrac{\partial \eta}{\partial \beta}  \right] \\
&=-X'  \left[ c''(\eta)\right]  X   
\end{align}

Next is the $p \times q$ mixed partial $\dfrac{\partial^2}{  \partial \beta \; \partial s}$.
\begin{align}
\dfrac{\partial^2}{ \partial \beta \;  \partial s}  \left[ l(\eta) - (1/2) s's   \right] &= \dfrac{\partial}{\partial \beta} \left\{  \left[ Y-c'(\eta)  \right]' ZA  \right\}\\
&= \dfrac{\partial}{\partial \beta} \left\{Y'ZA-  \left[ c'(\eta)  \right]' ZA  \right\} \\
&=- \dfrac{\partial}{\partial \beta} \left\{  \left[ c'(\eta)  \right]' ZA  \right\} \\
&=- \left[  \dfrac{\partial  c'(\eta)}{\partial \beta}  \right]' ZA  \\
&=-   \left[  \dfrac{\partial  c'(\eta)}{\partial \eta} \dfrac{\partial \eta}{\partial \beta}  \right]' ZA   \\
&=-   \left[ c''(\eta) X  \right]' ZA   \\
&=-X'   \left[ c''(\eta)   \right] ZA  
\end{align}


And last we have the $q \times p$ mixed partial $\dfrac{\partial^2}{  \partial \beta \; \partial s}= -AZ' [c''(\eta)] X.$  These four pieces specify the hessian matrix for the penalized likelihood. Trust can now perform the inner optimization to find $\tilde{\beta}$ and $\tilde{s}$. Trust will maximize the penalized likelihood.





The {\bf outer} optimization is done using \texttt{optim} with the default method of ``\texttt{Nelder-Mead.}'' This requires just the function value and no derivatives.  This optimization method was chosen because the optimization function already contains second derivatives of the cumulant function; requiring derivatives of the optimization function would in turn require higher-order derivatives of the cumulant.  

The default of \texttt{optim} is to minimize, but we'd like to  do maximization. Reversing the sign of the optimization function will turn the maximization into minimization.

If $\tilde{\beta}$ and $\tilde{s}$ are available from previous calls to the inner optimization function, then they are used here. Otherwise, the values are taken to be 0 and 1. The outer optimization's function is evaluated by first defining
\begin{align}
\tilde{\eta} &= X \tilde{\beta} +ZA \tilde{s}\\
l(\tilde{\eta}) &= Y' \tilde{\eta} - c(\tilde{\eta})\\
A&= \sum_k E_k \sigma_k.
\end{align}
Let $W$ be a diagonal matrix with elements $c''(\eta_i)$ on the diagonal. Then the quantity we'd like to maximize is the penalized quasi-likelihood:
\begin{align}
 l(\tilde{\eta}) - \dfrac{1}{2} \tilde{s}' \tilde{s} - \dfrac{1}{2} \log  \left| AZ' W ZA +I  \right| \\
\end{align}
Again, \texttt{optim} minimizes, so we have to minimize the negative value of the penalized quasi-likelihood in order to maximize the value of it.

We do need to be careful about the determinant. Let $AZ' W ZA +I= LL'$ where $L$ is the lower triangular matrix resulting from a Cholesky decomposition. Then
\begin{align}
\dfrac{1}{2} \log | AZ' W ZA +I | &= \dfrac{1}{2} \log |LL'|\\
&=\dfrac{1}{2} \log (|L|)^2 \\
&= \log |L|
\end{align}
Since $L$ is triangular, the determinant is just the product of the diagonal elements. Let $l_i$ be the diagonal elements of $L$. Then
\begin{align}
\dfrac{1}{2} \log | AZ' W ZA +I | &= \log \prod l_i \\
&= \sum \log l_i
\end{align}

 If I am worried about all variance components being zero, I could implement an eigendecomposition using the R function \texttt{eigen}. This would be more numerically stable, but is slower. Let $O$ be the matrix containing the eigenvectors and let $\Lambda$ be a diagonal matrix with the eigenvalues $\lambda_i$ on the diagonal. Then
\begin{align}
 &AZ' W ZA = O \Lambda O' 
\end{align}
Then we can rewrite the argument of the determinant as follows:
\begin{align}
& AZ' W ZA +I  = O \Lambda O' + I = O \Lambda O + OO'=O (I+\Lambda) O' 
\end{align}
This leads to the careful calculation of our determinant as follows:
\begin{align}
&   \left| AZ' W ZA +I \right| = 1 *  \prod_{i=1}^n (1+\lambda_i) *1\\
&\Rightarrow \log   | AZ' W ZA +I | = \sum \log(1+\lambda_i) 
\end{align}
The last quantity can be accurately calculated using the \texttt{log1p} function in R.

The outer optimization  uses $\tilde{\beta}$ and $\tilde{s}$ provided by the inner optimization, but it does not return them. To keep track of the most recent  $\tilde{s}$, so store them in an environment that I call ``cache.''  The purpose of  $\tilde{\beta}$ and $\tilde{s}$ is two-fold. First, if they are available from a previous iteration of the inner optimization, then they are used in the outer optimization of PQL.  Second, after PQL is finished, $\tilde{s}$ is used to help center the generated random effects.


The point of doing PQL is to construct a decent importance sampling distribution. Thus, the estimates don't have to be perfect.  It is possible that one of the $\sigma_k$ will be 0 according to PQL. If this happens, then I'll just use $\sigma_k = .01$ or something like that for the importance sampling distribution.





\bibliographystyle{apalike}
\bibliography{brref}

\appendix
\section{MCLA calculations}
The Monte Carlo log likelihood approximation is
\begin{align}
l_{m}(\theta) &=\log \dfrac{1}{m} \sum_{k=1}^mf_\theta(y|u_k)  \dfrac{ f_\theta(u_k)   }{\tilde{f}(u_k)}\\
&= \log \dfrac{1}{m} \sum_{k=1}^m  \dfrac{ f_\theta(y,u_k)   }{\tilde{f}(u_k)}.
\end{align}

\subsection{MCLA derivatives when $\tilde{f}$ depends on $\theta$} \label{sec:calcs}
When $\tilde{f}$ contains $\theta$, the gradient of the MCLA is
\begin{align}
\nabla l_m(\theta) &= \dfrac{ \nabla \left[ \sum_{k=1}^m  \dfrac{ f_\theta(y,u_k)   }{\tilde{f}(u_k)}  \right] }{\sum_{k=1}^m  \dfrac{ f_\theta(y,u_k)   }{\tilde{f}(u_k)}} \\
&= \dfrac{   \sum_{k=1}^m  \dfrac{\nabla f_\theta(y,u_k)   }{\tilde{f}(u_k)} - \dfrac{ f_\theta(y,u_k)  \nabla \tilde{f}(u_k) }{\left(\tilde{f}(u_k) \right)^2 } }{\sum_{k=1}^m  \dfrac{ f_\theta(y,u_k)   }{\tilde{f}(u_k)}} \\
&= \dfrac{   \sum_{k=1}^m  \dfrac{\nabla f_\theta(y,u_k)}{f_\theta(y,u_k)} \dfrac{f_\theta(y,u_k)}{\tilde{f}(u_k)} -
 \dfrac{ f_\theta(y,u_k)}{\tilde{f}(u_k)} \dfrac{ \nabla \tilde{f}(u_k) }{\tilde{f}(u_k) } }{\sum_{k=1}^m  \dfrac{ f_\theta(y,u_k)   }{\tilde{f}(u_k)}} \\
&= \dfrac{   \sum_{k=1}^m  \nabla \log f_\theta(y,u_k) \dfrac{f_\theta(y,u_k)}{\tilde{f}(u_k)} -
 \dfrac{ f_\theta(y,u_k)}{\tilde{f}(u_k)}  \nabla \log \tilde{f}(u_k)  }{\sum_{k=1}^m  \dfrac{ f_\theta(y,u_k)   }{\tilde{f}(u_k)}} \\
&= \dfrac{   \sum_{k=1}^m \left[ \nabla \log f_\theta(y,u_k)  -
   \nabla \log \tilde{f}(u_k)   \right]  \dfrac{ f_\theta(y,u_k)}{\tilde{f}(u_k)}  }{\sum_{k=1}^m  \dfrac{ f_\theta(y,u_k)   }{\tilde{f}(u_k)}} 
\end{align}

Then the Hessian of the MCLA is
\begin{align}
\nabla^2 l_m (\theta) &= \nabla \left[ \dfrac{   \sum_{k=1}^m \left[ \nabla \log f_\theta(y,u_k)  -
   \nabla \log \tilde{f}(u_k)   \right]  \dfrac{ f_\theta(y,u_k)}{\tilde{f}(u_k)}  }{\sum_{k=1}^m  \dfrac{ f_\theta(y,u_k)   }{\tilde{f}(u_k)}} \right] \\
&= \dfrac{   \sum_{k=1}^m \left[ \nabla^2 \log f_\theta(y,u_k)  -
   \nabla^2 \log \tilde{f}(u_k)   \right]  \dfrac{ f_\theta(y,u_k)}{\tilde{f}(u_k)}  }{\sum_{k=1}^m  \dfrac{ f_\theta(y,u_k)   }{\tilde{f}(u_k)}}\\
&+ \dfrac{   \sum_{k=1}^m \left[ \nabla \log f_\theta(y,u_k)  -
   \nabla \log \tilde{f}(u_k)   \right]  \nabla \left[ \dfrac{ f_\theta(y,u_k)}{\tilde{f}(u_k)} \right]  }{\sum_{k=1}^m  \dfrac{ f_\theta(y,u_k)   }{\tilde{f}(u_k)}}\\
&-\left[\dfrac{   \sum_{k=1}^m \left[ \nabla \log f_\theta(y,u_k)  -
   \nabla \log \tilde{f}(u_k)   \right]  \dfrac{ f_\theta(y,u_k)}{\tilde{f}(u_k)}  }{ \left( \sum_{k=1}^m  \dfrac{ f_\theta(y,u_k)   }{\tilde{f}(u_k)} \right)^2} \right] \nabla \left[ \sum_{k=1}^m  \dfrac{ f_\theta(y,u_k)   }{\tilde{f}(u_k)} \right]\\
&= \dfrac{   \sum_{k=1}^m \left[ \nabla^2 \log f_\theta(y,u_k)  -
   \nabla^2 \log \tilde{f}(u_k)   \right]  \dfrac{ f_\theta(y,u_k)}{\tilde{f}(u_k)}  }{\sum_{k=1}^m  \dfrac{ f_\theta(y,u_k)   }{\tilde{f}(u_k)}}\\
&+ \dfrac{   \sum_{k=1}^m \left[ \nabla \log f_\theta(y,u_k)  -
   \nabla \log \tilde{f}(u_k)   \right] \left[ \nabla \log f_\theta(y,u_k)  -
   \nabla \log \tilde{f}(u_k)   \right]'  \dfrac{ f_\theta(y,u_k)   }{\tilde{f}(u_k)}   }{\sum_{k=1}^m  \dfrac{ f_\theta(y,u_k)   }{\tilde{f}(u_k)}}\\
&-\left[\dfrac{   \sum_{k=1}^m \left[ \nabla \log f_\theta(y,u_k)  -  \nabla \log \tilde{f}(u_k)   \right]  \dfrac{ f_\theta(y,u_k)}{\tilde{f}(u_k)}  }{ \left( \sum_{k=1}^m  \dfrac{ f_\theta(y,u_k)   }{\tilde{f}(u_k)} \right)^2} \right] \left[  \nabla \log f_\theta(y,u_k)  -  \nabla \log \tilde{f}(u_k)     \right]'\\
&= \dfrac{   \sum_{k=1}^m \left[ \nabla^2 \log f_\theta(y,u_k)  -
   \nabla^2 \log \tilde{f}(u_k)   \right]  \dfrac{ f_\theta(y,u_k)}{\tilde{f}(u_k)}  }{\sum_{k=1}^m  \dfrac{ f_\theta(y,u_k)   }{\tilde{f}(u_k)}}\\
&+ \dfrac{   \sum_{k=1}^m \left[ \nabla \log f_\theta(y,u_k)  -
   \nabla \log \tilde{f}(u_k)   \right] \left[ \nabla \log f_\theta(y,u_k)  -
   \nabla \log \tilde{f}(u_k)   \right]'  \dfrac{ f_\theta(y,u_k)   }{\tilde{f}(u_k)}   }{\sum_{k=1}^m  \dfrac{ f_\theta(y,u_k)   }{\tilde{f}(u_k)}}\\
&- \left[ \nabla l_m(\theta)  \right] \left[ \nabla l_m(\theta)  \right]'
\end{align}
To reduce the risk of catastrophic cancellation, we can combine the last two terms of the Hessian:
\begin{align}
\nabla^2 l_m(\theta)&= \dfrac{   \sum_{k=1}^m \left[ \nabla^2 \log f_\theta(y,u_k)  -
   \nabla^2 \log \tilde{f}(u_k)   \right]  \dfrac{ f_\theta(y,u_k)}{\tilde{f}(u_k)}  }{\sum_{k=1}^m  \dfrac{ f_\theta(y,u_k)   }{\tilde{f}(u_k)}}\\
&+ \dfrac{   \sum_{k=1}^m \left[ \nabla \log f_\theta(y,u_k)  -
   \nabla \log \tilde{f}(u_k) - \nabla l_m(\theta)   \right] \left[ \nabla \log f_\theta(y,u_k)  -
   \nabla \log \tilde{f}(u_k) -\nabla l_m(\theta)  \right]'  \dfrac{ f_\theta(y,u_k)   }{\tilde{f}(u_k)}   }{\sum_{k=1}^m  \dfrac{ f_\theta(y,u_k)   }{\tilde{f}(u_k)}}
\end{align}
We are able to combine the last two terms because $\nabla l_m(\theta)$ is a weighted mean of $\nabla \log f_\theta (y,u_k)- \nabla \log \tilde{f}(u_k)$. Letting
\begin{align}
Z&=\nabla \log f_\theta (y,u_k)- \nabla \log \tilde{f}(u_k)
\end{align}
 we can use the following equality:
\begin{align}
E(ZZ')-E(Z)E(Z)' = \left[ E(Z-EZ)  \right]\left[ E(Z-EZ)  \right]'.
\end{align}



\subsection{MCLA derivatives when $\tilde{f}$ independent of $\theta$}\label{sec:calcsindep}

When $\tilde{f}$ is independent of $\theta$, the gradient vector of the MCLA with respect to $\theta$ is
\begin{align}
\nabla l_m(\theta)= \dfrac{\sum_{k=1}^m    \left( \nabla \log f_\theta(u_k,y)  \dfrac{f_\theta(u_k,y)   }{\tilde{f}(u_k)}\right) }{\sum_{k=1}^m \left( \dfrac{f_\theta(u_k,y)}{\tilde{f}(u_k)} \right) } 
\end{align}
and the Hessian matrix of the MCLA is
\begin{align}
\nabla^2 l_m(\theta)&= \dfrac{\sum_{k=1}^m    \left( \nabla^2 \log f_\theta(u_k,y)   \dfrac{f_\theta(u_k,y)}{\tilde{f}(u_k)} \right)}{\sum_{k=1}^m \left( \dfrac{f_\theta(u_k,y)}{\tilde{f}(u_k)} \right) }- \nabla l_m(\theta) (\nabla l_m(\theta) )'  \\
&+\dfrac{\sum_{k=1}^m    \left( \nabla \log f_\theta(u_k,y) (\nabla \log f_\theta(u_k,y))'   \dfrac{f_\theta(u_k,y)}{\tilde{f}(u_k)} \right)}{\sum_{k=1}^m \left( \dfrac{f_\theta(u_k,y)}{\tilde{f}(u_k)} \right) }.
\end{align}


\section{Central Limit Theorem for MCLA}
Define
\begin{align}
\gamma_1&= \int f_\theta(u,y) du\\
\gamma_2 &=\int \tilde{f}(u)du.
\end{align}
Recall the calculation for the MCLA gradient originally stated in  \eqref{eq:MCLAgradient}:
\begin{align}
\nabla l_m(\theta)&= \dfrac{\sum_{k=1}^m    \left( \nabla \log f_\theta(u_k,y) - \nabla \log \tilde{f} (u_k)  \right) \dfrac{f_\theta(u_k,y)}{\tilde{f}(u_k)} }{\sum_{k=1}^m \left( \dfrac{f_\theta(u_k,y)}{\tilde{f}(u_k)} \right) }\\
&=\dfrac{\sum_{k=1}^m     \nabla \log f_\theta(u_k,y)   \dfrac{f_\theta(u_k,y)}{\tilde{f}(u_k)} }{\sum_{k=1}^m \left( \dfrac{f_\theta(u_k,y)}{\tilde{f}(u_k)} \right) }   -\dfrac{\sum_{k=1}^m     \nabla \log \tilde{f}(u_k)   \dfrac{f_\theta(u_k,y)}{\tilde{f}(u_k)} }{\sum_{k=1}^m \left( \dfrac{f_\theta(u_k,y)}{\tilde{f}(u_k)} \right) }
\end{align}

 Note that both the numerator and denominator are sample means. By the law of large numbers, the numerators and denominator  each converge to their true means. That is,
\begin{align}
\dfrac{1}{m}\sum_{k=1}^m \nabla \log f_\theta (u_k,y)  \dfrac{f_\theta(u_k,y)}{\tilde{f}(u_k)} &\rightarrow  E_{\tilde{f}} \left[ \nabla \log f_\theta (u,y)  \dfrac{f_\theta(u,y)}{\tilde{f}(u)}  \right] \\
&= \int \nabla \log f_\theta (u,y)  \dfrac{f_\theta(u,y)}{\tilde{f}(u)} \dfrac{\tilde{f}(u)}{\gamma_2} du\\
&= \dfrac{\gamma_1}{\gamma_2} \int \nabla \log f_\theta (u,y)  \dfrac{f_\theta(u,y)}{\gamma_1}  du \\
&=\dfrac{\gamma_1}{\gamma_2} E_f \left[ \nabla \log f_\theta(u,y)  \right]
\end{align}
and
\begin{align}
\dfrac{1}{m}\sum_{k=1}^m \nabla \log \tilde{f}(u_k)  \dfrac{f_\theta(u_k,y)}{\tilde{f}(u_k)} &\rightarrow  E_{\tilde{f}} \left[ \nabla \log \tilde{f}(u)  \dfrac{f_\theta(u,y)}{\tilde{f}(u)}  \right] \\
&= \int \nabla \log \tilde{f}(u)  \dfrac{f_\theta(u,y)}{\tilde{f}(u)} \dfrac{\tilde{f}(u)}{\gamma_2} du\\
&= \dfrac{\gamma_1}{\gamma_2} \int \nabla \log \tilde{f}(u)  \dfrac{f_\theta(u,y)}{\gamma_1}  du \\
&=\dfrac{\gamma_1}{\gamma_2} E_f \left[ \nabla \log \tilde{f}(u)  \right]
\end{align}
and
\begin{align}
\dfrac{1}{m}\sum_{k=1}^m \dfrac{f_\theta(u_k,y)}{\tilde{f}(u_k)} &\rightarrow E_{\tilde{f}} \left[ \dfrac{f_\theta(u,y)}{\tilde{f}(u)}  \right] \\
&= \int \dfrac{f_\theta(u,y)}{\tilde{f}(u)} \dfrac{\tilde{f}(u)}{\gamma_2} du\\
&= \dfrac{\gamma_1}{\gamma_2} \int \dfrac{ f_\theta(u,y)}{\gamma_2} du \\
&= \dfrac{\gamma_1}{\gamma_2}
\end{align}
Then, by Slutsky's,
\begin{align}
\nabla l_m(\theta)&\rightarrow \dfrac{  \dfrac{\gamma_1}{\gamma_2} E_f \left[ \nabla \log f_\theta(u,y)  \right] }{\dfrac{\gamma_1}{\gamma_2}}-\dfrac{  \dfrac{\gamma_1}{\gamma_2} E_f \left[ \nabla \log \tilde{f}(u)  \right] }{\dfrac{\gamma_1}{\gamma_2}}\\
&=  E_f \left[ \nabla \log f_\theta(u,y) - \nabla \log \tilde{f}(u)  \right] \\
&=\nabla l(\theta)
\end{align}
In addition to a law of large numbers, we would like a Central Limit Theorem for $\nabla l_m(\theta)$. In other words, the quantity
\begin{align}
&\sqrt{m} \left[  \dfrac{\dfrac{1}{m}\sum_{k=1}^m    \left( \nabla \log f_\theta(u_k,y) - \nabla \log \tilde{f}(u_k) \right)  \dfrac{f_\theta(u_k,y)}{\tilde{f}(u_k)} }{\dfrac{1}{m} \sum_{k=1}^m \left( \dfrac{f_\theta(u_k,y)}{\tilde{f}(u_k)} \right) }- l(\theta)  \right] \\
&=
\dfrac{\dfrac{1}{\sqrt{m}}\sum_{k=1}^m    \left( \nabla \log f_\theta(u_k,y)  - \nabla \log \tilde{f}(u_k) \right) \dfrac{f_\theta(u_k,y)}{\tilde{f}(u_k)} }{\dfrac{1}{m} \sum_{k=1}^m \left( \dfrac{f_\theta(u_k,y)}{\tilde{f}(u_k)} \right) }- \sqrt{m}\;  l(\theta)  \\
&=\dfrac{\dfrac{1}{\sqrt{m}}\sum_{k=1}^m    \left( \nabla \log f_\theta(u_k,y) - \nabla \log \tilde{f}(u_k) \right) \dfrac{f_\theta(u_k,y)}{\tilde{f}(u_k)} 
 - l(\theta) \dfrac{1}{\sqrt{m}}\sum_{k=1}^m  \dfrac{f_\theta(u_k,y)}{\tilde{f}(u_k)} }{\dfrac{1}{m} \sum_{k=1}^m  \dfrac{f_\theta(u_k,y)}{\tilde{f}(u_k)} }   
\end{align}
will have a normal distribution if and only if the variances of
\begin{align}
\sum_{k=1}^m  \dfrac{f_\theta(u_k,y)}{\tilde{f}(u_k)}
\end{align}
and
\begin{align}
\sum_{k=1}^m     \nabla \log f_\theta(u_k,y)\dfrac{f_\theta(u_k,y)}{\tilde{f}(u_k)} 
\end{align}
and
\begin{align}
\sum_{k=1}^m     \nabla \log \tilde{f}(u_k)\dfrac{f_\theta(u_k,y)}{\tilde{f}(u_k)} 
\end{align}
are each finite.
First, we want to show that
\begin{align}
\sum_{k=1}^m \dfrac{f_\theta(u_k)}{\tilde{f}(u_k)}
\end{align}
has finite variance. This is true if and only if 
\begin{align}
\int \dfrac{f_\theta(u)^2}{\tilde{f}(u)} du < \infty.
\end{align}
We see:
\begin{align}
\int \dfrac{f_\theta(u)^2}{\tilde{f}(u)} du &= \int \dfrac{N(u|0,D)^2}{p_1 N(u|0,D)+p_2 N(u|u^*, D^*) + p_3 N(u|u^*, ((Z'  c''(X \beta^*+Zu^*) Z +(D^*)^{-1}   )^{-1})} du \\
& \leq \int \dfrac{N(u|0,D)^2}{p_1 N(u|0,D)} du \\
&= \dfrac{1}{p_1} \int N(u|0,D) du \\
&= \dfrac{1}{p_1}.
\end{align}
Therefore $\sum_{k=1}^m f_\theta(u_k)$ has finite variance as long as $p_1\neq 0$.



Second, we want to show that
\begin{align}
\sum_{k=1}^m \nabla \log f_\theta (u_k,y) \dfrac{f_\theta(u_k,y)}{\tilde{f}(u_k)}
\end{align}
 has finite variance. That is, we want to show the existence of
\begin{align}
\int \dfrac{N(u|0,D)^2 \left[\nabla \left(\log f_\theta(y|u)+\log f_\theta (u) \right) \right]^2}{p_1 N(u|0,D)+p_2 N(u|u^*, D^*) + p_3 N(u|u^*, ((Z'  c''(X \beta^*+Zu^*) Z +(D^*)^{-1}   )^{-1})} du.
\end{align}
That is, we want to show the existence of
\begin{align}
\int &\dfrac{N(u|0,D)^2 \left[\nabla \left(\log f_\theta(y|u)+\log f_\theta (u) \right) \right]^2}{p_1 N(u|0,D)+p_2 N(u|u^*, D^*) + p_3 N(u|u^*, ((Z'  c''(X \beta^*+Zu^*) Z +(D^*)^{-1}   )^{-1})} du \\
&\leq \int  \dfrac{N(u|0,D)^2 \left[\nabla \left(\log f_\theta(y|u) + \log f_\theta (u) \right) \right]^2}{p_1 N(u|0,D)} du  \\
&\leq  \int \dfrac{N(u|0,D)^2 \left[ \dfrac{\partial}{\partial \beta} \log f_\theta(y|u) \, \, \dfrac{\partial}{\partial \nu} \log f_\theta (u)  \right]^2}{p_1 N(u|0,D)} du  \\
&\leq \dfrac{1}{p_1}  \int N(u|0,D) \left[ \dfrac{\partial}{\partial \beta}\log f_\theta(y|u) \, \, \dfrac{\partial}{\partial \nu} \log f_\theta (u)  \right]^2 du.
\end{align}
By the Cauchy-Schwartz inequality, 
\begin{align}
  &\int N(u|0,D) \left[ \dfrac{\partial}{\partial \beta}\log f_\theta(y|u) \, \, \dfrac{\partial}{\partial \nu} \log f_\theta (u)  \right]^2 du \\
& \leq \left[  \int N(u|0,D) \left[  \dfrac{\partial}{\partial \nu} \log f_\theta (u)  \right]^2 du \right]^{1/2}  \left[  \int N(u|0,D) \left[ \dfrac{\partial}{\partial \beta}\log f_\theta(y|u)   \right]^2 du \right]^{1/2} .
\end{align}
Therefore, I need to show that each of these two integrals is finite.  I will start with the first of the two integrals: 
\begin{align}
\int N(u|0,D) \left[  \dfrac{\partial}{\partial \nu} \log f_\theta(u)  \right]^2 du. 
\end{align}
Recall the notation from section \ref{sec:Ddiag}.  If
\begin{align}
\int N(u_t|0,D_t) \left[  \dfrac{\partial}{\partial \nu_t} \log f_\theta(u)  \right]^2 du_t< \infty 
\end{align}
for every $t=1,...,T$, then
\begin{align}
\int N(u|0,D) \left[  \dfrac{\partial}{\partial \nu} \log f_\theta(u)  \right]^2 du < \infty
\end{align}
by Cauchy Schwartz.  Therefore, I will prove the integral is finite for the general case of $u_t$ and $\nu_t$. First, we recognize that our integral is actually an expectation of a function of a normal random variable:
\begin{align}
\int N(u_t|0,D_t) \left[  \dfrac{\partial}{\partial \nu_t} \log f_\theta(u)  \right]^2 du_t &=
\int \dfrac{1}{\nu_t^{q_t/2}} e^{-u_t'u_t/(2 \nu_t)} \left[ -\dfrac{q_t}{2 \nu_t} + \dfrac{u_t'u_t}{2 \nu_t^2}  \right]^2 du_t .
\end{align}
Normal distributions have finite moments of all orders, so we know that\begin{align}
\int N(u_t|0,D_t) \left[  \dfrac{\partial}{\partial \nu_t} \log f_\theta(u)  \right]^2 du_t < \infty.
\end{align}




Next, we want to show 
\begin{align}
\int N(u|0,D) \left[\dfrac{\partial}{\partial \beta} \log f_\theta(y|u)   \right]^2 du < \infty.
\end{align}
 Recall that $\eta=X \beta +Z u$. Letting $\dfrac{\partial}{\partial \eta} c(\eta)=\mu$, we see 
\begin{align}
\int N(u|0,D) \left[\dfrac{\partial}{\partial \beta} \log f_\theta(y|u)   \right]^2 du &= \int N(u|0,D) \left[ (Y'- \mu') X X'(Y- \mu)   \right] du
%&\propto  \int N(u|0,D) \mu' XX' Y du + \int N(u|0,D) \mu' X X' \mu du   .
\end{align}
We will consider this integral for the cases of $Y|u$ being a Bernoulli and a Poisson random variable. When $Y|u$ is Bernoulli, then $0 \leq \mu \leq 1.$ Therefore,
\begin{align}
\int N(u|0,D) \left[ (Y'- \mu') X X'(Y- \mu)   \right] du
\end{align}
exists and is finite.
When $Y|u$ is a Poisson random variable, then for any  $\eta$, 
\begin{align}
\dfrac{\partial}{\partial \eta} c(\eta) = e^\eta.
\end{align}
Then
\begin{align}
\int N(u|0,D) \left[ (Y'- \mu') X X'(Y- \mu)   \right] du &\propto \int N(u|0,D)  e^{\eta} e^{\eta}    du \\
&\propto \int N(u|0,D) e^{2Zu} du 
\end{align}
exists and is finite.

Third and lastly, we want to show that 
\begin{align}
\sum_{k=1}^m \nabla \log \tilde{f} (u_k) \dfrac{f_\theta(u_k,y)}{\tilde{f}(u_k)}
\end{align}
 has finite variance. That is, we want to show the existence of
\begin{align}
\int \dfrac{N(u|0,D)^2 \left[\nabla \log \tilde{f}u) \right]^2}{p_1 N(u|0,D)+p_2 N(u|u^*, D^*) + p_3 N(u|u^*, ((Z'  c''(X \beta^*+Zu^*) Z +(D^*)^{-1}   )^{-1})} du.
\end{align}
We see that
\begin{align}
\int& \dfrac{N(u|0,D)^2 \left[\nabla \log \tilde{f}u) \right]^2}{p_1 N(u|0,D)+p_2 N(u|u^*, D^*) + p_3 N(u|u^*, ((Z'  c''(X \beta^*+Zu^*) Z +(D^*)^{-1}   )^{-1})} du\\
&\leq  \int \dfrac{N(u|0,D)^2 \left[\nabla \log \tilde{f}u) \right]^2}{p_1 N(u|0,D)} du\\
&= \dfrac{1}{p_1} \int N(u|0,D) \left[\nabla \log \tilde{f}u) \right]^2 du\\
&=\dfrac{1}{p_1} \int N(u|0,D) \left[  \dfrac{p_1 \dfrac{\partial}{\partial \nu} N(u|0,D)}{p_1 N(u|0,D)+p_2 N(u|u^*,D^*)+p_3 N(u|u^*, ((Z'  c''(X \beta^*+Zu^*) Z +(D^*)^{-1}   )^{-1})}   \right]^2 du\\
&\leq\dfrac{1}{p_1} \int N(u|0,D) \left[  \dfrac{p_1 \dfrac{\partial}{\partial \nu} N(u|0,D)}{p_1 N(u|0,D)}   \right]^2 du\\
&=\dfrac{1}{p_1} \int N(u|0,D) \left[  \dfrac{ \dfrac{\partial}{\partial \nu} N(u|0,D)}{ N(u|0,D)}   \right]^2 du\\
&= \dfrac{1}{p_1} \int \dfrac{\left[ \dfrac{\partial}{\partial \nu} N(u|0,D)  \right]^2}{N(u|0,D)} du \\
\end{align}






Therefore, it is proven that 
\begin{align}
\int \dfrac{N(u|0,D)^2 \left[\nabla \left(\log f_\theta(y|u)+\log f_\theta (u) \right) \right]^2}{p_1 N(u|0,D)+p_2 N(u|u^*, D^*) + p_3 N(u|u^*, ((Z'  c''(X \beta^*+Zu^*) Z +(D^*)^{-1}   )^{-1})} du 
\end{align}
exists and is finite. Therefore, since  the gradient of the MCLA has finite variance, we can conclude the gradient of the MCLA has a Central Limit Theorem.

%
%Next, we need to show that the hessian of the MCLA has finite variance. Again, it is enough to show that
%\begin{align}
%\int \dfrac{N(u|0,D)^2 h(u)^2}{p_1 N(u|0,D)+p_2 N(u|u^*, D^*) + p_3 N(u|u^*, ((Z'  c''(X \beta^*+Zu^*) Z +(D^*)^{-1}   )^{-1})} du < \infty
%\end{align}


%\subsection{Boundedness of importance weights}
%We want to make sure that the importance weights will be bounded when using this distribution. The importance weight for a vector $u_k$ is $\dfrac{f_\theta(y,u_k)}{\tilde{f}(u_k)}$. Since $f_\theta(y,u_k)< \infty$, 
%\begin{align}
%\dfrac{f_\theta(y,u_k)}{\tilde{f}(u_k)} < \infty \Longleftrightarrow \tilde{f}(u_k) >0.
%\end{align}
%
%We start with
%\begin{align}
% \tilde{f}(u_k) &= p_1  f(u_k \, | \, 0, D)+p_2  f(u_k \, | \, u^*, D^*)+p_3  f(u_k \, | \, u^*, (Z'  c''(X \beta^*+Zu^*) Z +(D^*)^{-1}   )^{-1})\\
%&\geq p_1  f(u_k \, | \, 0, D) \\
%& \geq p_1 (2 \pi)^{-q/2} \; |(D^*)^{-1/2}|  \; e^{- u' (D^{*})^{-1}u}
%\end{align}
%In order to show that $\tilde{f}(u_k)>0$, we need to show that both $ |(D^*)^{-1/2}|$ and  $e^{- u' (D^{*})^{-1}u}$ are positive. 
%
% First, I will show that $ |(D^*)^{-1/2}|>0$.Since  $(D^*)^{-1/2}$ is invertible, its determinant must be nonzero.  Since $D^*$ is positive semi-definite, then $(D^*)^{-1/2}$ is also positive semi-definite. Thus the eigenvalues of $(D^*)^{-1/2}$ are neither zero nor negative; they must be positive. An eigendecomposition tells us $|(D^*)^{-1/2}|$ is the product of its eigenvalues. Therefore, $|(D^*)^{-1/2}| >0$. 
%
%Next, I will show that $e^{- u' (D^{*})^{-1}u}>0$.  Since $D^*$ is a covariance matrix, it is positive semi-definite.  By definition, for any vector $a_1$, 
%\begin{align}
%a_1' D^* a_1 \geq 0
%\end{align}
%For every vector $a_2$, there exists an $a_1$ such that $a_2=D^*a_1$. Then
%\begin{align}
%a_2' (D^*)^{-1} a_2 &= (D^* a_1)' (D^*)^{-1} D^* a_1\\
%&= a_1' D^* (D^*)^{-1} D^* a_1\\
%&= a_1' D^* a_1\\
%& \geq 0
%\end{align}
%Therefore,   $(D^*)^{-1}$ is also positive semi-definite. Then for any vector of random effects $u$,
%\begin{align}
% u' (D^*)^{-1} u \geq 0 
%\end{align}
%This means that
%\begin{align}   e^{- u' (D^{*})^{-1}u} >0
%\end{align}
%Therefore,
%\begin{align}
% \tilde{f}(u_k) &\geq p_1 (2 \pi)^{q/2} \; |(D^*)^{-1/2}|  \; e^{- u' (D^{*})^{-1}u} >0
%\end{align}
%




\end{document}
